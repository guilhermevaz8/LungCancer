{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3367729a",
   "metadata": {},
   "source": [
    "# Exploração de modelos para a previsão de Cancro do Pulmão com base em TAC's\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução e objetivos\n",
    "O primeiro projecto desta unidade curricular, Laboratórios de IA e CD, consiste em usar imagens como dados de input, mais especificamente de Tomografias Computorizadas (TACs), do tronco humano, de modo a fazer uma classificação quanto à presença ou não de cancro do pulmão no paciente.\n",
    "\n",
    "O objetivo desta unidade curricular(Lab IA & CD), assim como deste trabalho, é aprofundar os nossos conhecimentos na área da IA e CD, assim como fomentar as nossas capacidades de comunicação, de trabalho em equipa e de desenvolvimento de software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas utilizadas\n",
    "\n",
    "A maioria das bibliotecas utilizadas já são nossas conhecidas de outras UCs, mas decidimos destacar a utilização da biblioteca \"radiomics\", pois foi a primeira vez que a utilizámos, tendo sido utilizada na obtenção das features através das imagens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "ba7496e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T14:37:00.173855Z",
     "start_time": "2023-10-12T14:37:00.085680Z"
    }
   },
   "outputs": [],
   "source": [
    "import pylidc as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylidc as pl\n",
    "from pylidc.utils import consensus\n",
    "import SimpleITK as sitk\n",
    "import six\n",
    "from radiomics import featureextractor\n",
    "import pandas as pd\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e0d106",
   "metadata": {},
   "source": [
    "Utilizámos como label as anotações dos radiologistas, por isso, vamos apenas usar as imagens dos pacientes que têm essas anotações. \n",
    "\n",
    "O primeiro passo foi extrair as informações das imagens usando a biblioteca radiomics. A cada conjunto de caracteristicas vamos atribuir o id do paciente correspondente e o nódulo em questão, de modo a deixar o paciente certo com o conjunto de caracteristicas e nódulo correspondente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "e1fb4a99",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-12T14:37:01.803169Z"
    },
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "Error closing cursor\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Campião\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\engine\\result.py\", line 2293, in _fetchall_impl\n",
      "    return list(self.iterator)\n",
      "  File \"C:\\Users\\Campião\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\orm\\loading.py\", line 191, in chunks\n",
      "    fetch = cursor._raw_all_rows()\n",
      "  File \"C:\\Users\\Campião\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\engine\\result.py\", line 546, in _raw_all_rows\n",
      "    rows = self._fetchall_impl()\n",
      "  File \"C:\\Users\\Campião\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\engine\\cursor.py\", line 2102, in _fetchall_impl\n",
      "    return self.cursor_strategy.fetchall(self, self.cursor)\n",
      "  File \"C:\\Users\\Campião\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\engine\\cursor.py\", line 1139, in fetchall\n",
      "    self.handle_exception(result, dbapi_cursor, e)\n",
      "  File \"C:\\Users\\Campião\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\engine\\cursor.py\", line 1080, in handle_exception\n",
      "    result.connection._handle_dbapi_exception(\n",
      "  File \"C:\\Users\\Campião\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\engine\\base.py\", line 2342, in _handle_dbapi_exception\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"C:\\Users\\Campião\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\engine\\cursor.py\", line 1135, in fetchall\n",
      "    rows = dbapi_cursor.fetchall()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Campião\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\engine\\base.py\", line 2199, in _safe_close_cursor\n",
      "    cursor.close()\n",
      "sqlite3.ProgrammingError: Cannot operate on a closed database.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Campião\\LIACD\\A3-S1\\LabIACD\\LungCancer\\LabIACDreal.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Campi%C3%A3o/LIACD/A3-S1/LabIACD/LungCancer/LabIACDreal.ipynb#Y350sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m patient_id \u001b[39m=\u001b[39m scan\u001b[39m.\u001b[39mpatient_id\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Campi%C3%A3o/LIACD/A3-S1/LabIACD/LungCancer/LabIACDreal.ipynb#Y350sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# Clusterize the annotations for the scan and retrieve all nodules\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Campi%C3%A3o/LIACD/A3-S1/LabIACD/LungCancer/LabIACDreal.ipynb#Y350sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m nods \u001b[39m=\u001b[39m scan\u001b[39m.\u001b[39;49mcluster_annotations()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Campi%C3%A3o/LIACD/A3-S1/LabIACD/LungCancer/LabIACDreal.ipynb#Y350sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Iterate through all nodules of the patient\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Campi%C3%A3o/LIACD/A3-S1/LabIACD/LungCancer/LabIACDreal.ipynb#Y350sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mfor\u001b[39;00m anns \u001b[39min\u001b[39;00m nods:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Campi%C3%A3o/LIACD/A3-S1/LabIACD/LungCancer/LabIACDreal.ipynb#Y350sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39m# Perform consensus clustering with a 50% agreement level\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pylidc\\Scan.py:439\u001b[0m, in \u001b[0;36mScan.cluster_annotations\u001b[1;34m(self, metric, tol, factor, min_tol, return_distance_matrix, verbose)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N):\n\u001b[0;32m    438\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m,N):\n\u001b[1;32m--> 439\u001b[0m         D[i,j] \u001b[39m=\u001b[39m D[j,i] \u001b[39m=\u001b[39m metric(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mannotations[i],\n\u001b[0;32m    440\u001b[0m                                  \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mannotations[j])\n\u001b[0;32m    442\u001b[0m adjacency \u001b[39m=\u001b[39m D \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m tol\n\u001b[0;32m    443\u001b[0m nnods, cids \u001b[39m=\u001b[39m connected_components(adjacency, directed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pylidc\\annotation_distance_metrics.py:27\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39minvalid `which` value.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m metrics[\u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m a,b: pairdist(a,b,\u001b[39m'\u001b[39;49m\u001b[39mmin\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     28\u001b[0m metrics[\u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m a,b: pairdist(a,b,\u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     29\u001b[0m metrics[\u001b[39m'\u001b[39m\u001b[39mavg\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m a,b: pairdist(a,b,\u001b[39m'\u001b[39m\u001b[39mavg\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pylidc\\annotation_distance_metrics.py:16\u001b[0m, in \u001b[0;36mpairdist\u001b[1;34m(ann1, ann2, which)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpairdist\u001b[39m(ann1, ann2, which):\n\u001b[0;32m      7\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39m    Compute the pairwise euclidean distance between \u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m    the contour boundary points, and return the \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m        One of 'min', 'max', or 'avg'.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     dists \u001b[39m=\u001b[39m cdist(ann1\u001b[39m.\u001b[39mcontours_matrix,\n\u001b[1;32m---> 16\u001b[0m                   ann2\u001b[39m.\u001b[39;49mcontours_matrix)\n\u001b[0;32m     18\u001b[0m     \u001b[39mif\u001b[39;00m   which \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     19\u001b[0m         \u001b[39mreturn\u001b[39;00m dists\u001b[39m.\u001b[39mmin()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pylidc\\Annotation.py:969\u001b[0m, in \u001b[0;36mAnnotation.contours_matrix\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    964\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcontours_matrix\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    965\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    966\u001b[0m \u001b[39m    All the contour index values a 3D numpy array.\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    968\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mvstack([c\u001b[39m.\u001b[39mto_matrix(include_k\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 969\u001b[0m                             \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcontours,\n\u001b[0;32m    970\u001b[0m                                     key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m c: c\u001b[39m.\u001b[39mimage_z_position)])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\orm\\attributes.py:566\u001b[0m, in \u001b[0;36mInstrumentedAttribute.__get__\u001b[1;34m(self, instance, owner)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    565\u001b[0m     \u001b[39mraise\u001b[39;00m orm_exc\u001b[39m.\u001b[39mUnmappedInstanceError(instance) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m--> 566\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimpl\u001b[39m.\u001b[39;49mget(state, dict_)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\orm\\attributes.py:1086\u001b[0m, in \u001b[0;36mAttributeImpl.get\u001b[1;34m(self, state, dict_, passive)\u001b[0m\n\u001b[0;32m   1083\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m passive \u001b[39m&\u001b[39m CALLABLES_OK:\n\u001b[0;32m   1084\u001b[0m     \u001b[39mreturn\u001b[39;00m PASSIVE_NO_RESULT\n\u001b[1;32m-> 1086\u001b[0m value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fire_loader_callables(state, key, passive)\n\u001b[0;32m   1088\u001b[0m \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m PASSIVE_NO_RESULT \u001b[39mor\u001b[39;00m value \u001b[39mis\u001b[39;00m NO_VALUE:\n\u001b[0;32m   1089\u001b[0m     \u001b[39mreturn\u001b[39;00m value\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\orm\\attributes.py:1121\u001b[0m, in \u001b[0;36mAttributeImpl._fire_loader_callables\u001b[1;34m(self, state, key, passive)\u001b[0m\n\u001b[0;32m   1119\u001b[0m     \u001b[39mreturn\u001b[39;00m callable_(state, passive)\n\u001b[0;32m   1120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallable_:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallable_(state, passive)\n\u001b[0;32m   1122\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1123\u001b[0m     \u001b[39mreturn\u001b[39;00m ATTR_EMPTY\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\orm\\strategies.py:966\u001b[0m, in \u001b[0;36mLazyLoader._load_for_state\u001b[1;34m(self, state, passive, loadopt, extra_criteria, extra_options, alternate_effective_path, execution_options)\u001b[0m\n\u001b[0;32m    960\u001b[0m     \u001b[39melif\u001b[39;00m (\n\u001b[0;32m    961\u001b[0m         \u001b[39mnot\u001b[39;00m passive \u001b[39m&\u001b[39m PassiveFlag\u001b[39m.\u001b[39mSQL_OK\n\u001b[0;32m    962\u001b[0m         \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m passive \u001b[39m&\u001b[39m PassiveFlag\u001b[39m.\u001b[39mRELATED_OBJECT_OK\n\u001b[0;32m    963\u001b[0m     ):\n\u001b[0;32m    964\u001b[0m         \u001b[39mreturn\u001b[39;00m LoaderCallableStatus\u001b[39m.\u001b[39mPASSIVE_NO_RESULT\n\u001b[1;32m--> 966\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_emit_lazyload(\n\u001b[0;32m    967\u001b[0m     session,\n\u001b[0;32m    968\u001b[0m     state,\n\u001b[0;32m    969\u001b[0m     primary_key_identity,\n\u001b[0;32m    970\u001b[0m     passive,\n\u001b[0;32m    971\u001b[0m     loadopt,\n\u001b[0;32m    972\u001b[0m     extra_criteria,\n\u001b[0;32m    973\u001b[0m     extra_options,\n\u001b[0;32m    974\u001b[0m     alternate_effective_path,\n\u001b[0;32m    975\u001b[0m     execution_options,\n\u001b[0;32m    976\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\orm\\strategies.py:1133\u001b[0m, in \u001b[0;36mLazyLoader._emit_lazyload\u001b[1;34m(self, session, state, primary_key_identity, passive, loadopt, extra_criteria, extra_options, alternate_effective_path, execution_options)\u001b[0m\n\u001b[0;32m   1127\u001b[0m stmt\u001b[39m.\u001b[39m_where_criteria \u001b[39m=\u001b[39m (lazy_clause,)\n\u001b[0;32m   1129\u001b[0m result \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39mexecute(\n\u001b[0;32m   1130\u001b[0m     stmt, params, execution_options\u001b[39m=\u001b[39mexecution_options\n\u001b[0;32m   1131\u001b[0m )\n\u001b[1;32m-> 1133\u001b[0m result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39;49munique()\u001b[39m.\u001b[39;49mscalars()\u001b[39m.\u001b[39;49mall()\n\u001b[0;32m   1135\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muselist:\n\u001b[0;32m   1136\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\engine\\result.py:1786\u001b[0m, in \u001b[0;36mScalarResult.all\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1778\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Sequence[_R]:\n\u001b[0;32m   1779\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return all scalar values in a list.\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \n\u001b[0;32m   1781\u001b[0m \u001b[39m    Equivalent to :meth:`_engine.Result.all` except that\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1784\u001b[0m \n\u001b[0;32m   1785\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1786\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_allrows()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\engine\\result.py:554\u001b[0m, in \u001b[0;36mResultInternal._allrows\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    550\u001b[0m post_creational_filter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_creational_filter\n\u001b[0;32m    552\u001b[0m make_row \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_row_getter\n\u001b[1;32m--> 554\u001b[0m rows \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fetchall_impl()\n\u001b[0;32m    555\u001b[0m made_rows: List[_InterimRowType[_R]]\n\u001b[0;32m    556\u001b[0m \u001b[39mif\u001b[39;00m make_row:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\engine\\result.py:1693\u001b[0m, in \u001b[0;36mFilterResult._fetchall_impl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1692\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fetchall_impl\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[_InterimRowType[Row[Any]]]:\n\u001b[1;32m-> 1693\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_real_result\u001b[39m.\u001b[39;49m_fetchall_impl()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\engine\\result.py:2293\u001b[0m, in \u001b[0;36mIteratorResult._fetchall_impl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2291\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_hard_closed()\n\u001b[0;32m   2292\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2293\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator)\n\u001b[0;32m   2294\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   2295\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_soft_close()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\orm\\loading.py:191\u001b[0m, in \u001b[0;36minstances.<locals>.chunks\u001b[1;34m(size)\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 191\u001b[0m     fetch \u001b[39m=\u001b[39m cursor\u001b[39m.\u001b[39;49m_raw_all_rows()\n\u001b[0;32m    193\u001b[0m \u001b[39mif\u001b[39;00m single_entity:\n\u001b[0;32m    194\u001b[0m     proc \u001b[39m=\u001b[39m process[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\engine\\result.py:546\u001b[0m, in \u001b[0;36mResultInternal._raw_all_rows\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    544\u001b[0m make_row \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_row_getter\n\u001b[0;32m    545\u001b[0m \u001b[39massert\u001b[39;00m make_row \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 546\u001b[0m rows \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fetchall_impl()\n\u001b[0;32m    547\u001b[0m \u001b[39mreturn\u001b[39;00m [make_row(row) \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m rows]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\engine\\cursor.py:2102\u001b[0m, in \u001b[0;36mCursorResult._fetchall_impl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fetchall_impl\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m-> 2102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcursor_strategy\u001b[39m.\u001b[39;49mfetchall(\u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcursor)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\engine\\cursor.py:1139\u001b[0m, in \u001b[0;36mCursorFetchStrategy.fetchall\u001b[1;34m(self, result, dbapi_cursor)\u001b[0m\n\u001b[0;32m   1137\u001b[0m     \u001b[39mreturn\u001b[39;00m rows\n\u001b[0;32m   1138\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 1139\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_exception(result, dbapi_cursor, e)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\engine\\cursor.py:1080\u001b[0m, in \u001b[0;36mCursorFetchStrategy.handle_exception\u001b[1;34m(self, result, dbapi_cursor, err)\u001b[0m\n\u001b[0;32m   1074\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhandle_exception\u001b[39m(\n\u001b[0;32m   1075\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1076\u001b[0m     result: CursorResult[Any],\n\u001b[0;32m   1077\u001b[0m     dbapi_cursor: Optional[DBAPICursor],\n\u001b[0;32m   1078\u001b[0m     err: \u001b[39mBaseException\u001b[39;00m,\n\u001b[0;32m   1079\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NoReturn:\n\u001b[1;32m-> 1080\u001b[0m     result\u001b[39m.\u001b[39;49mconnection\u001b[39m.\u001b[39;49m_handle_dbapi_exception(\n\u001b[0;32m   1081\u001b[0m         err, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, dbapi_cursor, result\u001b[39m.\u001b[39;49mcontext\n\u001b[0;32m   1082\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\engine\\base.py:2342\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[0;32m   2340\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2341\u001b[0m         \u001b[39massert\u001b[39;00m exc_info[\u001b[39m1\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2342\u001b[0m         \u001b[39mraise\u001b[39;00m exc_info[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mwith_traceback(exc_info[\u001b[39m2\u001b[39m])\n\u001b[0;32m   2343\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   2344\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reentrant_error\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sqlalchemy\\engine\\cursor.py:1135\u001b[0m, in \u001b[0;36mCursorFetchStrategy.fetchall\u001b[1;34m(self, result, dbapi_cursor)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetchall\u001b[39m(\n\u001b[0;32m   1130\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1131\u001b[0m     result: CursorResult[Any],\n\u001b[0;32m   1132\u001b[0m     dbapi_cursor: DBAPICursor,\n\u001b[0;32m   1133\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m   1134\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1135\u001b[0m         rows \u001b[39m=\u001b[39m dbapi_cursor\u001b[39m.\u001b[39;49mfetchall()\n\u001b[0;32m   1136\u001b[0m         result\u001b[39m.\u001b[39m_soft_close()\n\u001b[0;32m   1137\u001b[0m         \u001b[39mreturn\u001b[39;00m rows\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Configure the PyRadiomics feature extractor\n",
    "params = {\n",
    "    'binWidth': 25,  # Adjust parameters as needed\n",
    "    'resampledPixelSpacing': [1, 1, 1],  # Adjust spacing as needed\n",
    "    'featureClass': ['firstorder', 'shape', 'glcm', 'glrlm', 'glszm', 'ngtdm', 'gldm','glcmms','gldzm','ngtdmms','glrmms','glszmms']  # Include feature classes\n",
    "}\n",
    "\n",
    "extractor = featureextractor.RadiomicsFeatureExtractor(**params)\n",
    "\n",
    "# Consult all scans with annotations\n",
    "scans_with_annotations = pl.query(pl.Scan).filter(pl.Scan.annotations.any()).all()\n",
    "\n",
    "# Lists to store features and patient IDs\n",
    "features_list = []\n",
    "patient_ids = []\n",
    "\n",
    "# Variable to create unique IDs for nodules\n",
    "nodule_id_counter = 1\n",
    "\n",
    "# Iterate through all scans with annotations\n",
    "for scan in scans_with_annotations:\n",
    "    # Get the ID of the patient\n",
    "    patient_id = scan.patient_id\n",
    "    \n",
    "    # Clusterize the annotations for the scan and retrieve all nodules\n",
    "    nods = scan.cluster_annotations()\n",
    "    \n",
    "    # Iterate through all nodules of the patient\n",
    "    for anns in nods:\n",
    "        # Perform consensus clustering with a 50% agreement level\n",
    "        cmask, cbbox, masks = consensus(anns, clevel=0.5, pad=[(20, 20), (20, 20), (0, 0)])\n",
    "        \n",
    "        \n",
    "        # Convert the pixel array to a SimpleITK image\n",
    "        image = sitk.GetImageFromArray(cmask.astype(float))\n",
    "        \n",
    "        # Extract radiomic features using PyRadiomics\n",
    "        features = extractor.execute(image, image, label=1)  # Use label 1 for the nodule\n",
    "        \n",
    "        # Add the patient ID to the list\n",
    "        patient_ids.append(patient_id)\n",
    "        \n",
    "        # Add a unique ID for the nodule\n",
    "        features['Nodule_ID'] = f'Nodule_{nodule_id_counter}'\n",
    "        nodule_id_counter += 1\n",
    "        \n",
    "        # Add the features to the list\n",
    "        features_list.append(features)\n",
    "\n",
    "# Convert the list of features into a DataFrame\n",
    "features_df = pd.DataFrame(features_list)\n",
    "\n",
    "# Add a column \"Patient_ID\" to the DataFrame\n",
    "features_df['Patient_ID'] = patient_ids\n",
    "\n",
    "# Save the selected features to a CSV file\n",
    "features_df.to_csv('features.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50f9b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "max=9999999\n",
    "contador=0\n",
    "for scan in scans_with_annotations:\n",
    "    # Get the ID of the patient\n",
    "    patient_id = scan.patient_id\n",
    "    \n",
    "    # Clusterize the annotations for the scan and retrieve all nodules\n",
    "    nods = scan.cluster_annotations()\n",
    "    \n",
    "    # Iterate through all nodules of the patient\n",
    "    for anns in nods:\n",
    "        for ann in anns:\n",
    "            contador+=1\n",
    "        if contador<max:\n",
    "            max=contador\n",
    "        contador=0\n",
    "print(max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e19490",
   "metadata": {},
   "source": [
    "o passo seguinte foi a criação de outro df com as anotações para cada par nodulo-paciente;\n",
    "\n",
    "Para a label (malignancy) usamos uma média pesada, com pesos maiores no 1 e no 5 devido ao facto de a mesma indicar precisamente se o nódulo é maligno ou não.\n",
    "\n",
    "Para os restantes usamos o valor mais comum e quando não existe valor mais comum usamos a média normal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22ed240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n",
      "Failed to reduce all groups to <= 4 Annotations.\n",
      "Some nodules may be close and must be grouped manually.\n"
     ]
    }
   ],
   "source": [
    "# Variable to create unique IDs for nodules\n",
    "nodule_id_counter = 1\n",
    "data = []\n",
    "\n",
    "# Iterate through all scans with annotations\n",
    "for scan in scans_with_annotations:\n",
    "    # Get the ID of the patient\n",
    "    patient_id = scan.patient_id\n",
    "    \n",
    "    # Clusterize the annotations for the scan and retrieve all nodules\n",
    "    nods = scan.cluster_annotations()\n",
    "    \n",
    "    # Iterate through all nodules of the patient\n",
    "    for anns in nods:\n",
    "        # Calculate the weighted average for \"malignancy\" with different weights\n",
    "        malignancy_values = [ann.malignancy for ann in anns]\n",
    "        weighted_sum = sum(1.25*value if value == 5 else (0.75*value if value == 1 else value) for value in malignancy_values)\n",
    "        total_weight = sum(1.25 if value == 5 else (0.75 if value == 1 else 1) for value in malignancy_values)\n",
    "        mean_malignancy = weighted_sum / total_weight if total_weight > 0 else 0\n",
    "\n",
    "        # Calculate the mode (most common value) for other features\n",
    "        def calculate_mode(values):\n",
    "            try:\n",
    "                return statistics.mode(values)\n",
    "            except statistics.StatisticsError:\n",
    "                return np.mean(values)\n",
    "        \n",
    "        mode_subtely=calculate_mode([ann.subtlety for ann in anns])\n",
    "        mode_internalStructure = calculate_mode([ann.internalStructure for ann in anns])\n",
    "        mode_calcification = calculate_mode([ann.calcification for ann in anns])\n",
    "        mode_sphericity = calculate_mode([ann.sphericity for ann in anns])\n",
    "        mode_margin = calculate_mode([ann.margin for ann in anns])\n",
    "        mode_lobulation = calculate_mode([ann.lobulation for ann in anns])\n",
    "        mode_spiculation = calculate_mode([ann.spiculation for ann in anns])\n",
    "        mode_texture = calculate_mode([ann.texture for ann in anns])\n",
    "        \n",
    "\n",
    "        # Create a dictionary to store the data\n",
    "        row = {\n",
    "            'Patient_ID': patient_id,\n",
    "            'Nodule_ID': f'Nodule_{nodule_id_counter}',\n",
    "            'subtlety': mode_subtely,\n",
    "            'internalStructure': mode_internalStructure,\n",
    "            'calcification': mode_calcification,\n",
    "            'sphericity': mode_sphericity,\n",
    "            'margin': mode_margin,\n",
    "            'lobulation': mode_lobulation,\n",
    "            'spiculation': mode_spiculation,\n",
    "            'texture': mode_texture,\n",
    "            'malignancy': mean_malignancy\n",
    "        }\n",
    "        \n",
    "        data.append(row)\n",
    "        nodule_id_counter += 1\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('annotations.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0764fafdd79e9",
   "metadata": {},
   "source": [
    "## Tratamento de Dados\n",
    "#### Bibliotecas utilizadas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376679b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd214c31",
   "metadata": {},
   "source": [
    "Ler as tabelas e criar os valores da label com base na malignancy, isto é, 0 se a malignancy for <= 3, 1 em caso contrário.\n",
    "\n",
    "Esta label indica se o nódulo do paciente em questão é cancerígeno ou não."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d990305f1ea56e0",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "features = pd.read_csv('features.csv')\n",
    "annot=pd.read_csv('annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72592ecc57441b7",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label1: 670 Label0: 1981\n"
     ]
    }
   ],
   "source": [
    "values=[]\n",
    "count1=0\n",
    "count0=0\n",
    "for value in annot['malignancy']:\n",
    "    if value>3:\n",
    "        values.append(1)\n",
    "        count1+=1\n",
    "    else:\n",
    "        values.append(0)\n",
    "        count0+=1\n",
    "y = values  \n",
    "print(f'Label1: {count1} Label0: {count0}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c025c1",
   "metadata": {},
   "source": [
    "É notório o grande desiquilibrio verificado nesta fase entre as classes, o que poderá afetar o modelo. \n",
    "\n",
    "Decidimos continuar o trabalho sem efetuar qualquer tipo de alteração nesta questão, apesar de haverem métodos possiveis para o fazer, como Data Augmentation/Reduction e de acreditarmos que se o fizéssemos teríamos melhores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui podemos visualizar todas as colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2a7708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diagnostics_Versions_PyRadiomics\n",
      "diagnostics_Versions_Numpy\n",
      "diagnostics_Versions_SimpleITK\n",
      "diagnostics_Versions_PyWavelet\n",
      "diagnostics_Versions_Python\n",
      "diagnostics_Configuration_Settings\n",
      "diagnostics_Configuration_EnabledImageTypes\n",
      "diagnostics_Image-original_Hash\n",
      "diagnostics_Image-original_Dimensionality\n",
      "diagnostics_Image-original_Spacing\n",
      "diagnostics_Image-original_Size\n",
      "diagnostics_Image-original_Mean\n",
      "diagnostics_Image-original_Minimum\n",
      "diagnostics_Image-original_Maximum\n",
      "diagnostics_Mask-original_Hash\n",
      "diagnostics_Mask-original_Spacing\n",
      "diagnostics_Mask-original_Size\n",
      "diagnostics_Mask-original_BoundingBox\n",
      "diagnostics_Mask-original_VoxelNum\n",
      "diagnostics_Mask-original_VolumeNum\n",
      "diagnostics_Mask-original_CenterOfMassIndex\n",
      "diagnostics_Mask-original_CenterOfMass\n",
      "diagnostics_Image-interpolated_Spacing\n",
      "diagnostics_Image-interpolated_Size\n",
      "diagnostics_Image-interpolated_Mean\n",
      "diagnostics_Image-interpolated_Minimum\n",
      "diagnostics_Image-interpolated_Maximum\n",
      "diagnostics_Mask-interpolated_Spacing\n",
      "diagnostics_Mask-interpolated_Size\n",
      "diagnostics_Mask-interpolated_BoundingBox\n",
      "diagnostics_Mask-interpolated_VoxelNum\n",
      "diagnostics_Mask-interpolated_VolumeNum\n",
      "diagnostics_Mask-interpolated_CenterOfMassIndex\n",
      "diagnostics_Mask-interpolated_CenterOfMass\n",
      "diagnostics_Mask-interpolated_Mean\n",
      "diagnostics_Mask-interpolated_Minimum\n",
      "diagnostics_Mask-interpolated_Maximum\n",
      "original_shape_Elongation\n",
      "original_shape_Flatness\n",
      "original_shape_LeastAxisLength\n",
      "original_shape_MajorAxisLength\n",
      "original_shape_Maximum2DDiameterColumn\n",
      "original_shape_Maximum2DDiameterRow\n",
      "original_shape_Maximum2DDiameterSlice\n",
      "original_shape_Maximum3DDiameter\n",
      "original_shape_MeshVolume\n",
      "original_shape_MinorAxisLength\n",
      "original_shape_Sphericity\n",
      "original_shape_SurfaceArea\n",
      "original_shape_SurfaceVolumeRatio\n",
      "original_shape_VoxelVolume\n",
      "original_firstorder_10Percentile\n",
      "original_firstorder_90Percentile\n",
      "original_firstorder_Energy\n",
      "original_firstorder_Entropy\n",
      "original_firstorder_InterquartileRange\n",
      "original_firstorder_Kurtosis\n",
      "original_firstorder_Maximum\n",
      "original_firstorder_MeanAbsoluteDeviation\n",
      "original_firstorder_Mean\n",
      "original_firstorder_Median\n",
      "original_firstorder_Minimum\n",
      "original_firstorder_Range\n",
      "original_firstorder_RobustMeanAbsoluteDeviation\n",
      "original_firstorder_RootMeanSquared\n",
      "original_firstorder_Skewness\n",
      "original_firstorder_TotalEnergy\n",
      "original_firstorder_Uniformity\n",
      "original_firstorder_Variance\n",
      "original_glcm_Autocorrelation\n",
      "original_glcm_ClusterProminence\n",
      "original_glcm_ClusterShade\n",
      "original_glcm_ClusterTendency\n",
      "original_glcm_Contrast\n",
      "original_glcm_Correlation\n",
      "original_glcm_DifferenceAverage\n",
      "original_glcm_DifferenceEntropy\n",
      "original_glcm_DifferenceVariance\n",
      "original_glcm_Id\n",
      "original_glcm_Idm\n",
      "original_glcm_Idmn\n",
      "original_glcm_Idn\n",
      "original_glcm_Imc1\n",
      "original_glcm_Imc2\n",
      "original_glcm_InverseVariance\n",
      "original_glcm_JointAverage\n",
      "original_glcm_JointEnergy\n",
      "original_glcm_JointEntropy\n",
      "original_glcm_MCC\n",
      "original_glcm_MaximumProbability\n",
      "original_glcm_SumAverage\n",
      "original_glcm_SumEntropy\n",
      "original_glcm_SumSquares\n",
      "original_gldm_DependenceEntropy\n",
      "original_gldm_DependenceNonUniformity\n",
      "original_gldm_DependenceNonUniformityNormalized\n",
      "original_gldm_DependenceVariance\n",
      "original_gldm_GrayLevelNonUniformity\n",
      "original_gldm_GrayLevelVariance\n",
      "original_gldm_HighGrayLevelEmphasis\n",
      "original_gldm_LargeDependenceEmphasis\n",
      "original_gldm_LargeDependenceHighGrayLevelEmphasis\n",
      "original_gldm_LargeDependenceLowGrayLevelEmphasis\n",
      "original_gldm_LowGrayLevelEmphasis\n",
      "original_gldm_SmallDependenceEmphasis\n",
      "original_gldm_SmallDependenceHighGrayLevelEmphasis\n",
      "original_gldm_SmallDependenceLowGrayLevelEmphasis\n",
      "original_glrlm_GrayLevelNonUniformity\n",
      "original_glrlm_GrayLevelNonUniformityNormalized\n",
      "original_glrlm_GrayLevelVariance\n",
      "original_glrlm_HighGrayLevelRunEmphasis\n",
      "original_glrlm_LongRunEmphasis\n",
      "original_glrlm_LongRunHighGrayLevelEmphasis\n",
      "original_glrlm_LongRunLowGrayLevelEmphasis\n",
      "original_glrlm_LowGrayLevelRunEmphasis\n",
      "original_glrlm_RunEntropy\n",
      "original_glrlm_RunLengthNonUniformity\n",
      "original_glrlm_RunLengthNonUniformityNormalized\n",
      "original_glrlm_RunPercentage\n",
      "original_glrlm_RunVariance\n",
      "original_glrlm_ShortRunEmphasis\n",
      "original_glrlm_ShortRunHighGrayLevelEmphasis\n",
      "original_glrlm_ShortRunLowGrayLevelEmphasis\n",
      "original_glszm_GrayLevelNonUniformity\n",
      "original_glszm_GrayLevelNonUniformityNormalized\n",
      "original_glszm_GrayLevelVariance\n",
      "original_glszm_HighGrayLevelZoneEmphasis\n",
      "original_glszm_LargeAreaEmphasis\n",
      "original_glszm_LargeAreaHighGrayLevelEmphasis\n",
      "original_glszm_LargeAreaLowGrayLevelEmphasis\n",
      "original_glszm_LowGrayLevelZoneEmphasis\n",
      "original_glszm_SizeZoneNonUniformity\n",
      "original_glszm_SizeZoneNonUniformityNormalized\n",
      "original_glszm_SmallAreaEmphasis\n",
      "original_glszm_SmallAreaHighGrayLevelEmphasis\n",
      "original_glszm_SmallAreaLowGrayLevelEmphasis\n",
      "original_glszm_ZoneEntropy\n",
      "original_glszm_ZonePercentage\n",
      "original_glszm_ZoneVariance\n",
      "original_ngtdm_Busyness\n",
      "original_ngtdm_Coarseness\n",
      "original_ngtdm_Complexity\n",
      "original_ngtdm_Contrast\n",
      "original_ngtdm_Strength\n",
      "Nodule_ID\n",
      "Patient_ID\n"
     ]
    }
   ],
   "source": [
    "for column in features.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcb88e3",
   "metadata": {},
   "source": [
    "Todas as colunas que mencionam \"diagnostics\" são referentes a variáveis de versões e de caracteristicas que são irrelevantes para o modelo, logo podemos eliminar.\n",
    "\n",
    "Isto deve-se ao facto de as features que decidimos manter estarem nomeadas com \"orginal_ngtdm_(nome da feature)\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eb52ed24bbcdd2",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_shape_Elongation\n",
      "original_shape_Flatness\n",
      "original_shape_LeastAxisLength\n",
      "original_shape_MajorAxisLength\n",
      "original_shape_Maximum2DDiameterColumn\n",
      "original_shape_Maximum2DDiameterRow\n",
      "original_shape_Maximum2DDiameterSlice\n",
      "original_shape_Maximum3DDiameter\n",
      "original_shape_MeshVolume\n",
      "original_shape_MinorAxisLength\n",
      "original_shape_Sphericity\n",
      "original_shape_SurfaceArea\n",
      "original_shape_SurfaceVolumeRatio\n",
      "original_shape_VoxelVolume\n",
      "original_firstorder_10Percentile\n",
      "original_firstorder_90Percentile\n",
      "original_firstorder_Energy\n",
      "original_firstorder_Entropy\n",
      "original_firstorder_InterquartileRange\n",
      "original_firstorder_Kurtosis\n",
      "original_firstorder_Maximum\n",
      "original_firstorder_MeanAbsoluteDeviation\n",
      "original_firstorder_Mean\n",
      "original_firstorder_Median\n",
      "original_firstorder_Minimum\n",
      "original_firstorder_Range\n",
      "original_firstorder_RobustMeanAbsoluteDeviation\n",
      "original_firstorder_RootMeanSquared\n",
      "original_firstorder_Skewness\n",
      "original_firstorder_TotalEnergy\n",
      "original_firstorder_Uniformity\n",
      "original_firstorder_Variance\n",
      "original_glcm_Autocorrelation\n",
      "original_glcm_ClusterProminence\n",
      "original_glcm_ClusterShade\n",
      "original_glcm_ClusterTendency\n",
      "original_glcm_Contrast\n",
      "original_glcm_Correlation\n",
      "original_glcm_DifferenceAverage\n",
      "original_glcm_DifferenceEntropy\n",
      "original_glcm_DifferenceVariance\n",
      "original_glcm_Id\n",
      "original_glcm_Idm\n",
      "original_glcm_Idmn\n",
      "original_glcm_Idn\n",
      "original_glcm_Imc1\n",
      "original_glcm_Imc2\n",
      "original_glcm_InverseVariance\n",
      "original_glcm_JointAverage\n",
      "original_glcm_JointEnergy\n",
      "original_glcm_JointEntropy\n",
      "original_glcm_MCC\n",
      "original_glcm_MaximumProbability\n",
      "original_glcm_SumAverage\n",
      "original_glcm_SumEntropy\n",
      "original_glcm_SumSquares\n",
      "original_gldm_DependenceEntropy\n",
      "original_gldm_DependenceNonUniformity\n",
      "original_gldm_DependenceNonUniformityNormalized\n",
      "original_gldm_DependenceVariance\n",
      "original_gldm_GrayLevelNonUniformity\n",
      "original_gldm_GrayLevelVariance\n",
      "original_gldm_HighGrayLevelEmphasis\n",
      "original_gldm_LargeDependenceEmphasis\n",
      "original_gldm_LargeDependenceHighGrayLevelEmphasis\n",
      "original_gldm_LargeDependenceLowGrayLevelEmphasis\n",
      "original_gldm_LowGrayLevelEmphasis\n",
      "original_gldm_SmallDependenceEmphasis\n",
      "original_gldm_SmallDependenceHighGrayLevelEmphasis\n",
      "original_gldm_SmallDependenceLowGrayLevelEmphasis\n",
      "original_glrlm_GrayLevelNonUniformity\n",
      "original_glrlm_GrayLevelNonUniformityNormalized\n",
      "original_glrlm_GrayLevelVariance\n",
      "original_glrlm_HighGrayLevelRunEmphasis\n",
      "original_glrlm_LongRunEmphasis\n",
      "original_glrlm_LongRunHighGrayLevelEmphasis\n",
      "original_glrlm_LongRunLowGrayLevelEmphasis\n",
      "original_glrlm_LowGrayLevelRunEmphasis\n",
      "original_glrlm_RunEntropy\n",
      "original_glrlm_RunLengthNonUniformity\n",
      "original_glrlm_RunLengthNonUniformityNormalized\n",
      "original_glrlm_RunPercentage\n",
      "original_glrlm_RunVariance\n",
      "original_glrlm_ShortRunEmphasis\n",
      "original_glrlm_ShortRunHighGrayLevelEmphasis\n",
      "original_glrlm_ShortRunLowGrayLevelEmphasis\n",
      "original_glszm_GrayLevelNonUniformity\n",
      "original_glszm_GrayLevelNonUniformityNormalized\n",
      "original_glszm_GrayLevelVariance\n",
      "original_glszm_HighGrayLevelZoneEmphasis\n",
      "original_glszm_LargeAreaEmphasis\n",
      "original_glszm_LargeAreaHighGrayLevelEmphasis\n",
      "original_glszm_LargeAreaLowGrayLevelEmphasis\n",
      "original_glszm_LowGrayLevelZoneEmphasis\n",
      "original_glszm_SizeZoneNonUniformity\n",
      "original_glszm_SizeZoneNonUniformityNormalized\n",
      "original_glszm_SmallAreaEmphasis\n",
      "original_glszm_SmallAreaHighGrayLevelEmphasis\n",
      "original_glszm_SmallAreaLowGrayLevelEmphasis\n",
      "original_glszm_ZoneEntropy\n",
      "original_glszm_ZonePercentage\n",
      "original_glszm_ZoneVariance\n",
      "original_ngtdm_Busyness\n",
      "original_ngtdm_Coarseness\n",
      "original_ngtdm_Complexity\n",
      "original_ngtdm_Contrast\n",
      "original_ngtdm_Strength\n"
     ]
    }
   ],
   "source": [
    "feat = features.iloc[:,37:-2] \n",
    "for column in feat.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac2dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela final com dados\n",
    "InputData=pd.concat([annot,feat],axis=1)\n",
    "InputData.to_csv('complete_data.csv',index=False)\n",
    "index=InputData.iloc[:,0:2]\n",
    "X = InputData.drop(InputData.columns[[0,1]],axis=1)\n",
    "X.drop(['malignancy'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70092cab",
   "metadata": {},
   "source": [
    "Decidimos fazer um StandardCaler de modo a por todas as varíaveis na mesma escala, e efetuamos a divisão do dataset em 70% training set e 30% test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5b81d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_continuous = scaler.fit_transform(X)\n",
    "\n",
    "scaled = pd.DataFrame(X_continuous, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664d132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação dos modelos e resultados iniciais\n",
    "# Implementação do primeiro modelo - Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e86bc5f",
   "metadata": {},
   "source": [
    "O primeiro modelo que decidimos criar foi um Random Forest. \n",
    "\n",
    "Tomamos esta decisão pois sabemos que o mesmo é capaz de lidar com a grande dimensionalidade dos dados e iterar nos parametros para obter um possível melhor resultado nestas condições.\n",
    "\n",
    "Optamos também por utilizar uma função GridSearchCV, que efetua cross-validation, o que permite treinar o modelo com conjuntos de treino diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30de13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zezam\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "180 fits failed out of a total of 540.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\zezam\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\zezam\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 476, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\Users\\zezam\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\zezam\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\zezam\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\zezam\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\zezam\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\zezam\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\zezam\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\zezam\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\zezam\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 189, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\zezam\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 969, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\zezam\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 265, in fit\n",
      "    check_scalar(\n",
      "  File \"c:\\Users\\zezam\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1476, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split == 1, must be >= 2.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\zezam\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.86199461 0.85929919 0.85876011\n",
      " 0.85822102 0.86091644 0.85768194        nan        nan        nan\n",
      " 0.86253369 0.86091644 0.86037736 0.86091644 0.86091644 0.85876011\n",
      "        nan        nan        nan 0.85929919 0.85822102 0.86091644\n",
      " 0.85983827 0.85929919 0.86037736        nan        nan        nan\n",
      " 0.85876011 0.86415094 0.86469003 0.86684636 0.86522911 0.86415094\n",
      "        nan        nan        nan 0.86199461 0.86630728 0.86522911\n",
      " 0.85768194 0.86576819 0.86415094        nan        nan        nan\n",
      " 0.86576819 0.86576819 0.86846361 0.85876011 0.86792453 0.86522911\n",
      "        nan        nan        nan 0.86576819 0.86954178 0.8690027\n",
      " 0.86576819 0.86576819 0.86522911        nan        nan        nan\n",
      " 0.86091644 0.86361186 0.8690027  0.85876011 0.86684636 0.86684636\n",
      "        nan        nan        nan 0.86199461 0.86415094 0.86576819\n",
      " 0.85822102 0.86738544 0.86684636        nan        nan        nan\n",
      " 0.86145553 0.86954178 0.86576819 0.86307278 0.86091644 0.86415094\n",
      "        nan        nan        nan 0.85660377 0.86630728 0.86630728\n",
      " 0.85606469 0.86576819 0.86253369        nan        nan        nan\n",
      " 0.86199461 0.86684636 0.86522911 0.85444744 0.86576819 0.86630728]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       574\n",
      "           1       0.77      0.68      0.72       222\n",
      "\n",
      "    accuracy                           0.85       796\n",
      "   macro avg       0.82      0.80      0.81       796\n",
      "weighted avg       0.85      0.85      0.85       796\n",
      "\n",
      "Accuracy: 0.8530150753768844\n",
      "Precision: 0.7692307692307693\n",
      "Recall: 0.6756756756756757\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_grid={'max_depth':[3,5,10,None],\n",
    "              'n_estimators':[10,100,200],\n",
    "              'min_samples_leaf':[1,2,3],\n",
    "              'min_samples_split':[1,2,3]\n",
    "           }\n",
    "\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(),param_grid,refit=True,verbose=1);\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "grid_predictions = grid.predict(X_test)\n",
    "print(classification_report(y_test,grid_predictions))\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, grid_predictions)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot();\n",
    "\n",
    "accuracy = accuracy_score(y_test, grid_predictions)\n",
    "precision = precision_score(y_test, grid_predictions)\n",
    "recall = recall_score(y_test, grid_predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2436e12",
   "metadata": {},
   "source": [
    "Fazendo uma análise preliminar dos resultados, podemos verificar que a accuracy está intermédia, assim como o recall.\n",
    "\n",
    "Acreditamos que equilibrar as classes pode ser uma possível solução para obter uma melhor accuracy, algo que será abordado mais à frente no trabalho."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568b7c1f",
   "metadata": {},
   "source": [
    "## Implementação do segundo modelo - SVM\n",
    "\n",
    "Optámos por implementar uma SVM (support vector machine), devido à sua particular eficiência em problemas de classificação como o do trabalho proposto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8f395f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "SVC(C=100, gamma=0.001)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.91       574\n",
      "           1       0.85      0.65      0.74       222\n",
      "\n",
      "    accuracy                           0.87       796\n",
      "   macro avg       0.86      0.80      0.83       796\n",
      "weighted avg       0.87      0.87      0.86       796\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "melhor=0\n",
    "\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid','linear']}\n",
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=1);\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "grid_predictions = grid.predict(X_test)\n",
    "print(classification_report(y_test,grid_predictions))\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, grid_predictions)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d421bf3d",
   "metadata": {},
   "source": [
    "O modelo SVM apresenta uma ligeira melhoria em termos de accuracy quando comparado ao random forrest implementado anteriormente. Isto deve-se ao facto de apresentar menos falsos positivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação do terceiro modelo - KNN\n",
    "\n",
    "Decidimos implementar o KNN pois é para nós um modelo já muito conhecido e de fácil implementação, por isso também a titulo de curiosidade decidimos comparar o seu desempenho com os restantes modelos implementados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d50878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.8706030150753769\n",
      "Precision: 0.8361581920903954\n",
      "Recall: 0.6666666666666666\n",
      "43\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "melhor=0\n",
    "\n",
    "for k in range(1,100):\n",
    "    # Você pode ajustar esse valor\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # Treine o classificador com os dados de treinamento\n",
    "    knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Faça previsões no conjunto de teste\n",
    "    y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "    # Calcule a precisão das previsões\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    if accuracy>melhor:\n",
    "        melhork=k\n",
    "        melhor=accuracy\n",
    "        melhorp=precision\n",
    "        melhorr=recall\n",
    "print(f\"Acurácia: {melhor}\")\n",
    "print(\"Precision:\", melhorp)\n",
    "print(\"Recall:\", melhorr)\n",
    "print(melhork)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado obtido não foi surpreendente, sendo muito parecido com o do random forest.\n",
    "\n",
    "Ainda assim, optámos por implementar um último modelo para ver se haveria alguma mudança na previsão.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação do quarto modelo - Rede neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5118ab",
   "metadata": {},
   "source": [
    "### Por ultimo criamos uma NN a iterar em vários parametros e a devolver o melhor modelo possivel.\n",
    "\n",
    "### Decidimos usar uma NN porque achamos que os dados são bastante complexos e se torna bastante dificil para um dos outros algoritmos detetar esses padrões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc5efe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "58/58 [==============================] - 1s 2ms/step - loss: 0.3919 - accuracy: 0.2518\n",
      "Epoch 2/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.2518\n",
      "Epoch 3/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.2518\n",
      "Epoch 4/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.2518\n",
      "Epoch 5/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.3139 - accuracy: 0.2518\n",
      "Epoch 6/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.3015 - accuracy: 0.2518\n",
      "Epoch 7/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2954 - accuracy: 0.2518\n",
      "Epoch 8/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2845 - accuracy: 0.2518\n",
      "Epoch 9/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2815 - accuracy: 0.2518\n",
      "Epoch 10/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2819 - accuracy: 0.2518\n",
      "Epoch 11/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.2814 - accuracy: 0.2518\n",
      "Epoch 12/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2696 - accuracy: 0.2518\n",
      "Epoch 13/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2781 - accuracy: 0.2518\n",
      "Epoch 14/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.2518\n",
      "Epoch 15/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.2574 - accuracy: 0.2518\n",
      "Epoch 16/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.2518\n",
      "Epoch 17/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2518 - accuracy: 0.2518\n",
      "Epoch 18/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.2526 - accuracy: 0.2518\n",
      "Epoch 19/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.2518\n",
      "Epoch 20/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2390 - accuracy: 0.2518\n",
      "Epoch 21/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2485 - accuracy: 0.2518\n",
      "Epoch 22/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2409 - accuracy: 0.2518\n",
      "Epoch 23/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.2351 - accuracy: 0.2518\n",
      "Epoch 24/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.2518\n",
      "Epoch 25/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2354 - accuracy: 0.2518\n",
      "Epoch 26/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.2518\n",
      "Epoch 27/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2338 - accuracy: 0.2518\n",
      "Epoch 28/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.2140 - accuracy: 0.2518\n",
      "Epoch 29/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2082 - accuracy: 0.2518\n",
      "Epoch 30/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.2518\n",
      "Epoch 31/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2148 - accuracy: 0.2518\n",
      "Epoch 32/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2143 - accuracy: 0.2518\n",
      "Epoch 33/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.1986 - accuracy: 0.2518\n",
      "Epoch 34/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.1975 - accuracy: 0.2518\n",
      "Epoch 35/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.1811 - accuracy: 0.2518\n",
      "Epoch 36/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.1801 - accuracy: 0.2518\n",
      "Epoch 37/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.2518\n",
      "Epoch 38/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.1891 - accuracy: 0.2518\n",
      "Epoch 39/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.1782 - accuracy: 0.2518\n",
      "Epoch 40/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1775 - accuracy: 0.2518\n",
      "Epoch 41/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1794 - accuracy: 0.2518\n",
      "Epoch 42/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1740 - accuracy: 0.2518\n",
      "Epoch 43/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1633 - accuracy: 0.2518\n",
      "Epoch 44/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.1469 - accuracy: 0.2518\n",
      "Epoch 45/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1546 - accuracy: 0.2518\n",
      "Epoch 46/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1567 - accuracy: 0.2518\n",
      "Epoch 47/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1383 - accuracy: 0.2518\n",
      "Epoch 48/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1577 - accuracy: 0.2518\n",
      "Epoch 49/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.2518\n",
      "Epoch 50/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.1461 - accuracy: 0.2518\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5005 - accuracy: 0.2550\n",
      "Epoch 1/50\n",
      "58/58 [==============================] - 1s 2ms/step - loss: 0.7697 - accuracy: 0.2518\n",
      "Epoch 2/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.2518\n",
      "Epoch 3/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.2518\n",
      "Epoch 4/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.2518\n",
      "Epoch 5/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.2518\n",
      "Epoch 6/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.2518\n",
      "Epoch 7/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.2518\n",
      "Epoch 8/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.2518\n",
      "Epoch 9/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.3411 - accuracy: 0.2518\n",
      "Epoch 10/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.2518\n",
      "Epoch 11/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.2518\n",
      "Epoch 12/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.2518\n",
      "Epoch 13/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.2518\n",
      "Epoch 14/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.2518\n",
      "Epoch 15/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.2518\n",
      "Epoch 16/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.2518\n",
      "Epoch 17/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.2518\n",
      "Epoch 18/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.2518\n",
      "Epoch 19/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.2518\n",
      "Epoch 20/50\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.2518\n",
      "Epoch 21/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.2518\n",
      "Epoch 22/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.2518\n",
      "Epoch 23/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.2518\n",
      "Epoch 24/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.2518\n",
      "Epoch 25/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.2518\n",
      "Epoch 26/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.2518\n",
      "Epoch 27/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.2518\n",
      "Epoch 28/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.2518\n",
      "Epoch 29/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.2518\n",
      "Epoch 30/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.2518\n",
      "Epoch 31/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.2518\n",
      "Epoch 32/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.2518\n",
      "Epoch 33/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.2518\n",
      "Epoch 34/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.2518\n",
      "Epoch 35/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.2518\n",
      "Epoch 36/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.2518\n",
      "Epoch 37/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.2518\n",
      "Epoch 38/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.5329 - accuracy: 0.2518\n",
      "Epoch 39/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.2518\n",
      "Epoch 40/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.2518\n",
      "Epoch 41/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.2518\n",
      "Epoch 42/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.2518\n",
      "Epoch 43/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.5328 - accuracy: 0.2518\n",
      "Epoch 44/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.5350 - accuracy: 0.2518\n",
      "Epoch 45/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.2518\n",
      "Epoch 46/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.5339 - accuracy: 0.2518\n",
      "Epoch 47/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.5338 - accuracy: 0.2518\n",
      "Epoch 48/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.2518\n",
      "Epoch 49/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5337 - accuracy: 0.2518\n",
      "Epoch 50/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.2518\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5389 - accuracy: 0.2550\n",
      "Epoch 1/50\n",
      "58/58 [==============================] - 1s 1ms/step - loss: 130.1373 - accuracy: 0.2518\n",
      "Epoch 2/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.6004 - accuracy: 0.2518\n",
      "Epoch 3/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.5946 - accuracy: 0.2518\n",
      "Epoch 4/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.2518\n",
      "Epoch 5/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.5656 - accuracy: 0.2518\n",
      "Epoch 6/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.5735 - accuracy: 0.2518\n",
      "Epoch 7/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.2518\n",
      "Epoch 8/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.2518\n",
      "Epoch 9/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.2518\n",
      "Epoch 10/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.5666 - accuracy: 0.2518\n",
      "Epoch 11/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.2518\n",
      "Epoch 12/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5653 - accuracy: 0.2518\n",
      "Epoch 13/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.5799 - accuracy: 0.2518\n",
      "Epoch 14/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.5671 - accuracy: 0.2518\n",
      "Epoch 15/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.5667 - accuracy: 0.2518\n",
      "Epoch 16/50\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.5698 - accuracy: 0.2518\n",
      "Epoch 17/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.2518\n",
      "Epoch 18/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.2518\n",
      "Epoch 19/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5728 - accuracy: 0.2518\n",
      "Epoch 20/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5683 - accuracy: 0.2518\n",
      "Epoch 21/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.2518\n",
      "Epoch 22/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.2518\n",
      "Epoch 23/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.2518\n",
      "Epoch 24/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.2518\n",
      "Epoch 25/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.2518\n",
      "Epoch 26/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.2518\n",
      "Epoch 27/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.2518\n",
      "Epoch 28/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.2518\n",
      "Epoch 29/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.2518\n",
      "Epoch 30/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.2518\n",
      "Epoch 31/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.2518\n",
      "Epoch 32/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.2518\n",
      "Epoch 33/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.2518\n",
      "Epoch 34/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.2518\n",
      "Epoch 35/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.2518\n",
      "Epoch 36/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.2518\n",
      "Epoch 37/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.2518\n",
      "Epoch 38/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5709 - accuracy: 0.2518\n",
      "Epoch 39/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.2518\n",
      "Epoch 40/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.2518\n",
      "Epoch 41/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.2518\n",
      "Epoch 42/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.2518\n",
      "Epoch 43/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.2518\n",
      "Epoch 44/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.2518\n",
      "Epoch 45/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.2518\n",
      "Epoch 46/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.2518\n",
      "Epoch 47/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.2518\n",
      "Epoch 48/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.2518\n",
      "Epoch 49/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5705 - accuracy: 0.2518\n",
      "Epoch 50/50\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.2518\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6078 - accuracy: 0.2550\n",
      "Epoch 1/100\n",
      "58/58 [==============================] - 1s 1ms/step - loss: 0.3866 - accuracy: 0.2518\n",
      "Epoch 2/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.2518\n",
      "Epoch 3/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.2518\n",
      "Epoch 4/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3030 - accuracy: 0.2518\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.3038 - accuracy: 0.2518\n",
      "Epoch 6/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2959 - accuracy: 0.2518\n",
      "Epoch 7/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.2855 - accuracy: 0.2518\n",
      "Epoch 8/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.2997 - accuracy: 0.2518\n",
      "Epoch 9/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.2879 - accuracy: 0.2518\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.2980 - accuracy: 0.2518\n",
      "Epoch 11/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.2750 - accuracy: 0.2518\n",
      "Epoch 12/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2829 - accuracy: 0.2518\n",
      "Epoch 13/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.2756 - accuracy: 0.2518\n",
      "Epoch 14/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2696 - accuracy: 0.2518\n",
      "Epoch 15/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2598 - accuracy: 0.2518\n",
      "Epoch 16/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2578 - accuracy: 0.2518\n",
      "Epoch 17/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.2590 - accuracy: 0.2518\n",
      "Epoch 18/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.2524 - accuracy: 0.2518\n",
      "Epoch 19/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.2628 - accuracy: 0.2518\n",
      "Epoch 20/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.2518\n",
      "Epoch 21/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2351 - accuracy: 0.2518\n",
      "Epoch 22/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2417 - accuracy: 0.2518\n",
      "Epoch 23/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.2518\n",
      "Epoch 24/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.2391 - accuracy: 0.2518\n",
      "Epoch 25/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.2518\n",
      "Epoch 26/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2322 - accuracy: 0.2518\n",
      "Epoch 27/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.2518\n",
      "Epoch 28/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2301 - accuracy: 0.2518\n",
      "Epoch 29/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.2110 - accuracy: 0.2518\n",
      "Epoch 30/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.2074 - accuracy: 0.2518\n",
      "Epoch 31/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.2069 - accuracy: 0.2518\n",
      "Epoch 32/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.1928 - accuracy: 0.2518\n",
      "Epoch 33/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1878 - accuracy: 0.2518\n",
      "Epoch 34/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.2518\n",
      "Epoch 35/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.2518\n",
      "Epoch 36/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1682 - accuracy: 0.2518\n",
      "Epoch 37/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1731 - accuracy: 0.2518\n",
      "Epoch 38/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.2518\n",
      "Epoch 39/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.2054 - accuracy: 0.2518\n",
      "Epoch 40/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.1638 - accuracy: 0.2518\n",
      "Epoch 41/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1726 - accuracy: 0.2518\n",
      "Epoch 42/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.1519 - accuracy: 0.2518\n",
      "Epoch 43/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1458 - accuracy: 0.2518\n",
      "Epoch 44/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.1481 - accuracy: 0.2518\n",
      "Epoch 45/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1363 - accuracy: 0.2518\n",
      "Epoch 46/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.1378 - accuracy: 0.2518\n",
      "Epoch 47/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.1479 - accuracy: 0.2518\n",
      "Epoch 48/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1412 - accuracy: 0.2518\n",
      "Epoch 49/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1522 - accuracy: 0.2518\n",
      "Epoch 50/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1464 - accuracy: 0.2518\n",
      "Epoch 51/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1382 - accuracy: 0.2518\n",
      "Epoch 52/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.1269 - accuracy: 0.2518\n",
      "Epoch 53/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1328 - accuracy: 0.2518\n",
      "Epoch 54/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1237 - accuracy: 0.2518\n",
      "Epoch 55/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1029 - accuracy: 0.2518\n",
      "Epoch 56/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.0938 - accuracy: 0.2518\n",
      "Epoch 57/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1012 - accuracy: 0.2518\n",
      "Epoch 58/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.1411 - accuracy: 0.2518\n",
      "Epoch 59/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1237 - accuracy: 0.2518\n",
      "Epoch 60/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.1100 - accuracy: 0.2518\n",
      "Epoch 61/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1080 - accuracy: 0.2518\n",
      "Epoch 62/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.0900 - accuracy: 0.2518\n",
      "Epoch 63/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.0929 - accuracy: 0.2518\n",
      "Epoch 64/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.0882 - accuracy: 0.2518\n",
      "Epoch 65/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.0919 - accuracy: 0.2518\n",
      "Epoch 66/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1619 - accuracy: 0.2518\n",
      "Epoch 67/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1266 - accuracy: 0.2518\n",
      "Epoch 68/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1069 - accuracy: 0.2518\n",
      "Epoch 69/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.0855 - accuracy: 0.2518\n",
      "Epoch 70/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.2518\n",
      "Epoch 71/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1066 - accuracy: 0.2518\n",
      "Epoch 72/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.0993 - accuracy: 0.2518\n",
      "Epoch 73/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.0861 - accuracy: 0.2518\n",
      "Epoch 74/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.0820 - accuracy: 0.2518\n",
      "Epoch 75/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.2518\n",
      "Epoch 76/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.0836 - accuracy: 0.2518\n",
      "Epoch 77/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.0692 - accuracy: 0.2518\n",
      "Epoch 78/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.2518\n",
      "Epoch 79/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.0835 - accuracy: 0.2518\n",
      "Epoch 80/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.0804 - accuracy: 0.2518\n",
      "Epoch 81/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1088 - accuracy: 0.2518\n",
      "Epoch 82/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1185 - accuracy: 0.2518\n",
      "Epoch 83/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1126 - accuracy: 0.2518\n",
      "Epoch 84/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.0951 - accuracy: 0.2518\n",
      "Epoch 85/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.0752 - accuracy: 0.2518\n",
      "Epoch 86/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.2518\n",
      "Epoch 87/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.2518\n",
      "Epoch 88/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.2518\n",
      "Epoch 89/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.2518\n",
      "Epoch 90/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.0706 - accuracy: 0.2518\n",
      "Epoch 91/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.0487 - accuracy: 0.2518\n",
      "Epoch 92/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.0447 - accuracy: 0.2518\n",
      "Epoch 93/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.0453 - accuracy: 0.2518\n",
      "Epoch 94/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 0.2518\n",
      "Epoch 95/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.0399 - accuracy: 0.2518\n",
      "Epoch 96/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.2518\n",
      "Epoch 97/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1265 - accuracy: 0.2518\n",
      "Epoch 98/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1706 - accuracy: 0.2518\n",
      "Epoch 99/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1237 - accuracy: 0.2518\n",
      "Epoch 100/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.1403 - accuracy: 0.2518\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.9978 - accuracy: 0.2550\n",
      "Epoch 1/100\n",
      "58/58 [==============================] - 1s 2ms/step - loss: 1.1173 - accuracy: 0.2518\n",
      "Epoch 2/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.2518\n",
      "Epoch 3/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.2518\n",
      "Epoch 4/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.2518\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.4303 - accuracy: 0.2518\n",
      "Epoch 6/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.5292 - accuracy: 0.2518\n",
      "Epoch 7/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.2518\n",
      "Epoch 8/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.5602 - accuracy: 0.2518\n",
      "Epoch 9/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.2518\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.2518\n",
      "Epoch 11/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.7276 - accuracy: 0.2518\n",
      "Epoch 12/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.2518\n",
      "Epoch 13/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.2518\n",
      "Epoch 14/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.2518\n",
      "Epoch 15/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.2518\n",
      "Epoch 16/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.2518\n",
      "Epoch 17/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.2518\n",
      "Epoch 18/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.2518\n",
      "Epoch 19/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.2518\n",
      "Epoch 20/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.2518\n",
      "Epoch 21/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.2518\n",
      "Epoch 22/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.2518\n",
      "Epoch 23/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.2518\n",
      "Epoch 24/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.2518\n",
      "Epoch 25/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.2518\n",
      "Epoch 26/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5653 - accuracy: 0.2518\n",
      "Epoch 27/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.2518\n",
      "Epoch 28/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.2518\n",
      "Epoch 29/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.2518\n",
      "Epoch 30/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.2518\n",
      "Epoch 31/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.2518\n",
      "Epoch 32/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.2518\n",
      "Epoch 33/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.2518\n",
      "Epoch 34/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.2518\n",
      "Epoch 35/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.2518\n",
      "Epoch 36/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.2518\n",
      "Epoch 37/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.2518\n",
      "Epoch 38/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.2518\n",
      "Epoch 39/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.2518\n",
      "Epoch 40/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.2518\n",
      "Epoch 41/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.2518\n",
      "Epoch 42/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.2518\n",
      "Epoch 43/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.2518\n",
      "Epoch 44/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.2518\n",
      "Epoch 45/100\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.2518\n",
      "Epoch 46/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.2518\n",
      "Epoch 47/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.2518\n",
      "Epoch 48/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.2518\n",
      "Epoch 49/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.2518\n",
      "Epoch 50/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.2518\n",
      "Epoch 51/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.2518\n",
      "Epoch 52/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5663 - accuracy: 0.2518\n",
      "Epoch 53/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.2518\n",
      "Epoch 54/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.2518\n",
      "Epoch 55/100\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.5667 - accuracy: 0.2518\n",
      "Epoch 56/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.2518\n",
      "Epoch 57/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.2518\n",
      "Epoch 58/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.2518\n",
      "Epoch 59/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.2518\n",
      "Epoch 60/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.2518\n",
      "Epoch 61/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.2518\n",
      "Epoch 62/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.2518\n",
      "Epoch 63/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.2518\n",
      "Epoch 64/100\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.5672 - accuracy: 0.2518\n",
      "Epoch 65/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.2518\n",
      "Epoch 66/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.2518\n",
      "Epoch 67/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.2518\n",
      "Epoch 68/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5639 - accuracy: 0.2518\n",
      "Epoch 69/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5696 - accuracy: 0.2518\n",
      "Epoch 70/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.2518\n",
      "Epoch 71/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.2518\n",
      "Epoch 72/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.2518\n",
      "Epoch 73/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.2518\n",
      "Epoch 74/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.2518\n",
      "Epoch 75/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.2518\n",
      "Epoch 76/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.2518\n",
      "Epoch 77/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.2518\n",
      "Epoch 78/100\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.5662 - accuracy: 0.2518\n",
      "Epoch 79/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.2518\n",
      "Epoch 80/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.2518\n",
      "Epoch 81/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5663 - accuracy: 0.2518\n",
      "Epoch 82/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5650 - accuracy: 0.2518\n",
      "Epoch 83/100\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.5654 - accuracy: 0.2518\n",
      "Epoch 84/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.2518\n",
      "Epoch 85/100\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.2518\n",
      "Epoch 86/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.2518\n",
      "Epoch 87/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.2518\n",
      "Epoch 88/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.2518\n",
      "Epoch 89/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.2518\n",
      "Epoch 90/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.2518\n",
      "Epoch 91/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5650 - accuracy: 0.2518\n",
      "Epoch 92/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.2518\n",
      "Epoch 93/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.2518\n",
      "Epoch 94/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.2518\n",
      "Epoch 95/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.2518\n",
      "Epoch 96/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.2518\n",
      "Epoch 97/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.2518\n",
      "Epoch 98/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.2518\n",
      "Epoch 99/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.2518\n",
      "Epoch 100/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.2518\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5739 - accuracy: 0.2550\n",
      "Epoch 1/100\n",
      "58/58 [==============================] - 1s 1ms/step - loss: 77.9559 - accuracy: 0.2518\n",
      "Epoch 2/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.6296 - accuracy: 0.2518\n",
      "Epoch 3/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.2518\n",
      "Epoch 4/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.2518\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.2518\n",
      "Epoch 6/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.2518\n",
      "Epoch 7/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.2518\n",
      "Epoch 8/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.2518\n",
      "Epoch 9/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.2518\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5972 - accuracy: 0.2518\n",
      "Epoch 11/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.2518\n",
      "Epoch 12/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5850 - accuracy: 0.2518\n",
      "Epoch 13/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.2518\n",
      "Epoch 14/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.2518\n",
      "Epoch 15/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.5468 - accuracy: 0.2518\n",
      "Epoch 16/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.2518\n",
      "Epoch 17/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.5465 - accuracy: 0.2518\n",
      "Epoch 18/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.5361 - accuracy: 0.2518\n",
      "Epoch 19/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.2518\n",
      "Epoch 20/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.2518\n",
      "Epoch 21/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.2518\n",
      "Epoch 22/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.2518\n",
      "Epoch 23/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.2518\n",
      "Epoch 24/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.5437 - accuracy: 0.2518\n",
      "Epoch 25/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.6031 - accuracy: 0.2518\n",
      "Epoch 26/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.2518\n",
      "Epoch 27/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.7268 - accuracy: 0.2518\n",
      "Epoch 28/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.2518\n",
      "Epoch 29/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.2518\n",
      "Epoch 30/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 1.2990 - accuracy: 0.2518\n",
      "Epoch 31/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.2518\n",
      "Epoch 32/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.2518\n",
      "Epoch 33/100\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.5607 - accuracy: 0.2518\n",
      "Epoch 34/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.2518\n",
      "Epoch 35/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.2518\n",
      "Epoch 36/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.2518\n",
      "Epoch 37/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.2518\n",
      "Epoch 38/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.2518\n",
      "Epoch 39/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.2518\n",
      "Epoch 40/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.2518\n",
      "Epoch 41/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.2518\n",
      "Epoch 42/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.2518\n",
      "Epoch 43/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.2518\n",
      "Epoch 44/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.2518\n",
      "Epoch 45/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.2518\n",
      "Epoch 46/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.2518\n",
      "Epoch 47/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5719 - accuracy: 0.2518\n",
      "Epoch 48/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.2518\n",
      "Epoch 49/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.2518\n",
      "Epoch 50/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.2518\n",
      "Epoch 51/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.2518\n",
      "Epoch 52/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.2518\n",
      "Epoch 53/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.5657 - accuracy: 0.2518\n",
      "Epoch 54/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.2518\n",
      "Epoch 55/100\n",
      "58/58 [==============================] - 0s 1ms/step - loss: 0.5668 - accuracy: 0.2518\n",
      "Epoch 56/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.2518\n",
      "Epoch 57/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.2518\n",
      "Epoch 58/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.2518\n",
      "Epoch 59/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.2518\n",
      "Epoch 60/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.2518\n",
      "Epoch 61/100\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 0.5659 - accuracy: 0.2518\n",
      "Epoch 62/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.2518\n",
      "Epoch 63/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.2518\n",
      "Epoch 64/100\n",
      "58/58 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.2518\n",
      "Epoch 65/100\n",
      "31/58 [===============>..............] - ETA: 0s - loss: 0.5669 - accuracy: 0.2530"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Campião\\LIACD\\A3-S1\\LabIACD\\LungCancer\\LabIACDreal.ipynb Cell 32\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Campi%C3%A3o/LIACD/A3-S1/LabIACD/LungCancer/LabIACDreal.ipynb#X41sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39mAdam(learningRate), metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Campi%C3%A3o/LIACD/A3-S1/LabIACD/LungCancer/LabIACDreal.ipynb#X41sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# Treine o modelo\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Campi%C3%A3o/LIACD/A3-S1/LabIACD/LungCancer/LabIACDreal.ipynb#X41sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X, y, epochs\u001b[39m=\u001b[39;49mepochs, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)  \u001b[39m# Use verbose=0 para evitar logs durante o treinamento\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Campi%C3%A3o/LIACD/A3-S1/LabIACD/LungCancer/LabIACDreal.ipynb#X41sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# Avalie o modelo\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Campi%C3%A3o/LIACD/A3-S1/LabIACD/LungCancer/LabIACDreal.ipynb#X41sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m loss, accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_test\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist(), y_test, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[0;32m    869\u001b[0m   )\n\u001b[0;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Suponha que você tenha um DataFrame 'X_train' com suas features e uma Serie 'y_train' com os rótulos/targets\n",
    "# Convertemos X_train e y_train para arrays NumPy\n",
    "\n",
    "\n",
    "X_NN = X_train.values.tolist()\n",
    "y_NN = y_train\n",
    "\n",
    "\n",
    "# Defina listas de parâmetros a serem testados\n",
    "hidden_layer_sizes = [64, 128, 256]\n",
    "epochs_list = [50, 100]\n",
    "learnRate = [0.01,0.1,0.5]\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "best_loss = None\n",
    "\n",
    "# Listas para armazenar accuracy e loss\n",
    "accuracies = []\n",
    "losses = []\n",
    "\n",
    "# Itere sobre as diferentes combinações de parâmetros\n",
    "for hidden_layers in hidden_layer_sizes:\n",
    "    for epochs in epochs_list:\n",
    "        for learningRate in learnRate:\n",
    "                # Crie o modelo\n",
    "            model = Sequential()\n",
    "            for i in range(2):\n",
    "                model.add(Dense(hidden_layers, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "                \n",
    "            model.add(Dense(1, activation='softmax'))  # Camada de output\n",
    "\n",
    "            # Compile o modelo\n",
    "            model.compile(loss='binary_crossentropy', optimizer=Adam(learningRate), metrics=['accuracy'])\n",
    "\n",
    "            # Treine o modelo\n",
    "            history = model.fit(X_NN, y_NN, epochs=epochs, verbose=0)  # Use verbose=0 para evitar logs durante o treinamento\n",
    "\n",
    "            # Avalie o modelo\n",
    "            loss, accuracy = model.evaluate(X_test.values.tolist(), y_test, verbose=0)\n",
    "\n",
    "            # Armazene accuracy e loss\n",
    "            accuracies.append(accuracy)\n",
    "            losses.append(loss)\n",
    "        \n",
    "            # Verifique se este é o melhor modelo até agora\n",
    "            if accuracy > best_accuracy:\n",
    "                best_hidden_layer_sizes =hidden_layers\n",
    "                best_epochs_list = epochs\n",
    "                best_accuracy = accuracy\n",
    "                best_model = model\n",
    "                best_loss = loss\n",
    "\n",
    "# O melhor modelo é armazenado em 'best_model'\n",
    "print(f\"Melhor Acurácia encontrada: {best_accuracy:.2f}\")\n",
    "print(f\"Loss do Melhor Modelo: {best_loss:.2f}\")\n",
    "print(f\"melhor numero de camadas ocultas: {best_hidden_layer_sizes}\")\n",
    "print(f\"Melhor numero de epochs: {best_epochs_list}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00df3396",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = best_model.evaluate(X_test.values.tolist(), y_test, verbose=0)      \n",
    "print(loss)\n",
    "print(accuracy)\n",
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f966cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (model.predict(X_test.values.tolist()) > 0.5).astype(int)\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred_bool = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alteração nos dados - Data augmentation e redution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a00b8d9",
   "metadata": {},
   "source": [
    "Apesar do output da rede neuronal ter demonstrado claras melhorias em relação aos modelos anteriores, decidimos ainda equilibrar o número de labels, quer por aumentação quer por diminuição.\n",
    "\n",
    "Para o fazer, utilizamos a biblioteca \"imblearn\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71e40d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 5, 7, 8, 10, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 34, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 84, 85, 86, 88, 89, 91, 93, 95, 96, 97, 98, 99, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 126, 127, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 157, 158, 160, 161, 162, 166, 167, 168, 169, 171, 173, 174, 175, 176, 177, 178, 179, 181, 182, 184, 185, 186, 187, 188, 189, 190, 191, 192, 194, 195, 196, 197, 198, 200, 203, 210, 211, 213, 214, 216, 217, 220, 230, 231, 232, 233, 235, 238, 239, 241, 246, 247, 248, 249, 250, 252, 255, 256, 257, 259, 260, 263, 265, 266, 267, 268, 270, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 289, 290, 291, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 307, 310, 312, 314, 315, 316, 317, 318, 319, 321, 322, 323, 325, 326, 327, 328, 329, 330, 331, 333, 335, 338, 339, 340, 342, 344, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 361, 362, 363, 364, 365, 366, 367, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 386, 388, 390, 391, 392, 393, 394, 395, 396, 397, 399, 400, 402, 403, 407, 410, 412, 413, 414, 417, 419, 420, 421, 422, 423, 424, 427, 431, 432, 435, 436, 437, 438, 439, 441, 442, 443, 444, 445, 447, 449, 451, 452, 453, 454, 456, 457, 458, 461, 462, 463, 464, 465, 466, 467, 468, 470, 473, 475, 476, 477, 478, 479, 480, 482, 484, 485, 486, 487, 488, 489, 490, 491, 493, 496, 497, 498, 499, 500, 501, 502, 504, 505, 506, 507, 508, 509, 510, 511, 513, 517, 518, 519, 520, 521, 523, 524, 526, 527, 528, 529, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 546, 547, 548, 550, 551, 552, 553, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 567, 568, 569, 571, 572, 573, 575, 577, 579, 580, 584, 585, 586, 588, 589, 601, 602, 603, 604, 605, 606, 607, 608, 609, 611, 612, 613, 614, 615, 616, 617, 620, 622, 623, 624, 625, 627, 628, 632, 633, 634, 635, 636, 637, 638, 639, 640, 649, 651, 655, 659, 660, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 680, 681, 682, 684, 685, 686, 687, 688, 690, 691, 692, 693, 695, 696, 697, 698, 703, 704, 706, 707, 708, 709, 710, 711, 712, 714, 715, 720, 722, 723, 728, 729, 730, 731, 732, 733, 734, 735, 737, 739, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 753, 754, 755, 756, 757, 758, 760, 761, 762, 763, 764, 765, 766, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 782, 783, 784, 787, 788, 789, 796, 798, 800, 801, 802, 803, 805, 806, 816, 817, 818, 820, 821, 822, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 845, 846, 847, 848, 849, 851, 853, 854, 855, 856, 857, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 873, 874, 875, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 896, 897, 899, 902, 904, 905, 906, 907, 910, 911, 913, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 932, 933, 934, 935, 936, 938, 940, 944, 945, 947, 948, 949, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 964, 965, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 984, 986, 987, 988, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1010, 1015, 1016, 1018, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1030, 1031, 1032, 1033, 1034, 1035, 1037, 1038, 1039, 1040, 1044, 1045, 1046, 1047, 1049, 1050, 1051, 1052, 1053, 1055, 1057, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1071, 1072, 1073, 1074, 1075, 1076, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1093, 1096, 1097, 1100, 1102, 1103, 1105, 1107, 1109, 1110, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1159, 1160, 1161, 1162, 1163, 1165, 1166, 1168, 1169, 1170, 1171, 1173, 1174, 1175, 1177, 1178, 1179, 1180, 1181, 1186, 1187, 1188, 1190, 1192, 1195, 1197, 1199, 1200, 1202, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1222, 1223, 1224, 1225, 1226, 1228, 1231, 1232, 1233, 1234, 1236, 1237, 1238, 1239, 1240, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1259, 1261, 1262, 1263, 1265, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1278, 1279, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1305, 1307, 1309, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1322, 1323, 1324, 1325, 1326, 1327, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1337, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1354, 1358, 1360, 1361, 1362, 1363, 1364, 1365, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1403, 1406, 1407, 1408, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1440, 1441, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1453, 1455, 1456, 1457, 1458, 1460, 1461, 1462, 1464, 1465, 1466, 1467, 1468, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1496, 1497, 1499, 1500, 1501, 1502, 1503, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1548, 1549, 1552, 1553, 1554, 1555, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1570, 1571, 1572, 1573, 1574, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1594, 1595, 1596, 1597, 1599, 1600, 1601, 1602, 1604, 1605, 1606, 1608, 1609, 1610, 1611, 1613, 1614, 1615, 1616, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1632, 1633, 1634, 1635, 1637, 1638, 1641, 1643, 1645, 1647, 1649, 1650, 1651, 1652, 1653, 1654, 1656, 1657, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1698, 1699, 1700, 1701, 1704, 1706, 1711, 1712, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1738, 1739, 1740, 1741, 1742, 1743, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1754, 1755, 1756, 1757, 1758, 1760, 1761, 1762, 1765, 1766, 1773, 1774, 1776, 1777, 1778, 1780, 1781, 1782, 1783, 1784, 1786, 1787, 1788, 1789, 1790, 1792, 1794, 1796, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1814, 1815, 1816, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1842, 1843, 1846, 1847, 1848, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1869, 1871, 1872, 1873, 1877, 1878, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1901, 1902, 1904, 1906, 1908, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1923, 1924, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1936, 1937, 1938, 1940, 1941, 1942, 1943, 1947, 1951, 1952, 1953, 1956, 1957, 1959, 1961, 1962, 1963, 1964, 1965, 1966, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1981, 1982, 1983, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2007, 2009, 2010, 2011, 2012, 2013, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2025, 2026, 2027, 2029, 2030, 2032, 2034, 2035, 2037, 2038, 2039, 2040, 2042, 2043, 2044, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2070, 2071, 2072, 2073, 2075, 2076, 2077, 2078, 2080, 2081, 2082, 2083, 2084, 2085, 2086, 2087, 2088, 2089, 2090, 2091, 2092, 2093, 2094, 2095, 2097, 2098, 2099, 2100, 2101, 2102, 2103, 2104, 2105, 2106, 2107, 2108, 2109, 2111, 2112, 2113, 2114, 2115, 2116, 2118, 2119, 2120, 2121, 2123, 2124, 2125, 2126, 2127, 2128, 2129, 2130, 2131, 2134, 2135, 2136, 2137, 2140, 2141, 2142, 2143, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2151, 2152, 2154, 2155, 2156, 2158, 2159, 2160, 2162, 2163, 2164, 2167, 2168, 2169, 2170, 2171, 2172, 2174, 2175, 2177, 2178, 2179, 2180, 2181, 2182, 2183, 2184, 2185, 2186, 2187, 2188, 2189, 2191, 2192, 2193, 2194, 2195, 2196, 2199, 2200, 2201, 2202, 2203, 2204, 2205, 2206, 2207, 2209, 2210, 2212, 2214, 2215, 2216, 2217, 2218, 2220, 2221, 2222, 2223, 2224, 2227, 2228, 2229, 2230, 2232, 2233, 2234, 2235, 2236, 2237, 2238, 2241, 2242, 2243, 2244, 2246, 2247, 2248, 2249, 2250, 2251, 2252, 2253, 2254, 2255, 2256, 2257, 2258, 2259, 2260, 2262, 2264, 2269, 2270, 2271, 2272, 2273, 2274, 2275, 2276, 2277, 2278, 2279, 2280, 2284, 2285, 2286, 2287, 2288, 2290, 2291, 2292, 2293, 2294, 2295, 2297, 2299, 2300, 2302, 2303, 2304, 2305, 2306, 2307, 2308, 2309, 2311, 2312, 2313, 2314, 2315, 2317, 2318, 2320, 2321, 2323, 2324, 2325, 2326, 2327, 2328, 2329, 2331, 2332, 2333, 2335, 2338, 2340, 2341, 2342, 2344, 2345, 2346, 2347, 2348, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 2361, 2362, 2363, 2364, 2366, 2368, 2369, 2370, 2371, 2372, 2373, 2374, 2375, 2376, 2378, 2379, 2380, 2381, 2382, 2384, 2385, 2386, 2387, 2388, 2390, 2391, 2392, 2394, 2395, 2396, 2398, 2399, 2400, 2401, 2402, 2404, 2405, 2406, 2409, 2410, 2411, 2412, 2413, 2414, 2416, 2417, 2418, 2419, 2420, 2421, 2423, 2424, 2425, 2426, 2427, 2429, 2432, 2433, 2434, 2436, 2437, 2438, 2439, 2440, 2441, 2442, 2446, 2448, 2449, 2450, 2451, 2453, 2454, 2455, 2456, 2457, 2458, 2459, 2462, 2463, 2464, 2466, 2468, 2469, 2471, 2472, 2474, 2475, 2476, 2477, 2478, 2479, 2481, 2482, 2483, 2488, 2490, 2491, 2492, 2493, 2494, 2495, 2497, 2498, 2499, 2500, 2501, 2502, 2503, 2504, 2505, 2507, 2510, 2523, 2524, 2525, 2526, 2528, 2531, 2534, 2535, 2536, 2537, 2538, 2540, 2542, 2543, 2544, 2545, 2546, 2547, 2548, 2549, 2550, 2553, 2554, 2557, 2558, 2559, 2560, 2561, 2562, 2565, 2567, 2568, 2569, 2570, 2571, 2572, 2573, 2574, 2575, 2576, 2578, 2579, 2580, 2583, 2584, 2585, 2586, 2587, 2588, 2589, 2592, 2594, 2595, 2596, 2597, 2600, 2601, 2602, 2603, 2604, 2606, 2608, 2610, 2611, 2612, 2613, 2614, 2615, 2616, 2617, 2618, 2619, 2620, 2621, 2622, 2623, 2626, 2627, 2628, 2629, 2630, 2632, 2633, 2634, 2635, 2636, 2637, 2638, 2639, 2640, 2641, 2642, 2643, 2644, 2649, 2650]\n",
      "      subtlety  internalStructure  calcification  sphericity  margin  \\\n",
      "0            4                  1              6           4       4   \n",
      "1            5                  1              6           4       2   \n",
      "2            4                  1              5           5       5   \n",
      "3            5                  1              4           4       2   \n",
      "4            3                  1              6           5       5   \n",
      "...        ...                ...            ...         ...     ...   \n",
      "2646         4                  1              6           4       4   \n",
      "2647         1                  1              6           4       1   \n",
      "2648         2                  1              6           4       3   \n",
      "2649         5                  1              6           4       5   \n",
      "2650         5                  1              2           5       5   \n",
      "\n",
      "      lobulation  spiculation  texture  original_shape_Elongation  \\\n",
      "0              2            2        5                   0.848594   \n",
      "1              4            1        5                   0.845360   \n",
      "2              1            1        5                   0.879310   \n",
      "3              4            3        5                   0.956858   \n",
      "4              5            5        5                   0.779886   \n",
      "...          ...          ...      ...                        ...   \n",
      "2646           2            2        5                   0.793847   \n",
      "2647           1            1        1                   0.754255   \n",
      "2648           1            1        5                   0.564212   \n",
      "2649           1            1        5                   0.453474   \n",
      "2650           4            5        5                   0.909345   \n",
      "\n",
      "      original_shape_Flatness  ...  \\\n",
      "0                    0.219031  ...   \n",
      "1                    0.215045  ...   \n",
      "2                    0.289526  ...   \n",
      "3                    0.216692  ...   \n",
      "4                    0.595806  ...   \n",
      "...                       ...  ...   \n",
      "2646                 0.375133  ...   \n",
      "2647                 0.687954  ...   \n",
      "2648                 0.185778  ...   \n",
      "2649                 0.247844  ...   \n",
      "2650                 0.273192  ...   \n",
      "\n",
      "      original_glszm_SmallAreaHighGrayLevelEmphasis  \\\n",
      "0                                      2.761356e-07   \n",
      "1                                      3.299153e-07   \n",
      "2                                      8.650519e-04   \n",
      "3                                      6.666667e-01   \n",
      "4                                      3.684042e-06   \n",
      "...                                             ...   \n",
      "2646                                   9.467456e-06   \n",
      "2647                                   2.576463e-06   \n",
      "2648                                   2.799474e-05   \n",
      "2649                                   1.686625e-04   \n",
      "2650                                   6.666667e-01   \n",
      "\n",
      "      original_glszm_SmallAreaLowGrayLevelEmphasis  \\\n",
      "0                                     2.761356e-07   \n",
      "1                                     3.299153e-07   \n",
      "2                                     8.650519e-04   \n",
      "3                                     6.666667e-01   \n",
      "4                                     3.684042e-06   \n",
      "...                                            ...   \n",
      "2646                                  9.467456e-06   \n",
      "2647                                  2.576463e-06   \n",
      "2648                                  2.799474e-05   \n",
      "2649                                  1.686625e-04   \n",
      "2650                                  6.666667e-01   \n",
      "\n",
      "      original_glszm_ZoneEntropy  original_glszm_ZonePercentage  \\\n",
      "0                  -3.203427e-16                       0.000525   \n",
      "1                  -3.203427e-16                       0.000574   \n",
      "2                  -3.203427e-16                       0.029412   \n",
      "3                   9.182958e-01                       0.000823   \n",
      "4                  -3.203427e-16                       0.001919   \n",
      "...                          ...                            ...   \n",
      "2646               -3.203427e-16                       0.003077   \n",
      "2647               -3.203427e-16                       0.001605   \n",
      "2648               -3.203427e-16                       0.005291   \n",
      "2649               -3.203427e-16                       0.012987   \n",
      "2650                9.182958e-01                       0.000217   \n",
      "\n",
      "      original_glszm_ZoneVariance  original_ngtdm_Busyness  \\\n",
      "0                    0.000000e+00                      0.0   \n",
      "1                    0.000000e+00                      0.0   \n",
      "2                    0.000000e+00                      0.0   \n",
      "3                    2.949211e+06                      0.0   \n",
      "4                    0.000000e+00                      0.0   \n",
      "...                           ...                      ...   \n",
      "2646                 0.000000e+00                      0.0   \n",
      "2647                 0.000000e+00                      0.0   \n",
      "2648                 0.000000e+00                      0.0   \n",
      "2649                 0.000000e+00                      0.0   \n",
      "2650                 4.230773e+07                      0.0   \n",
      "\n",
      "      original_ngtdm_Coarseness  original_ngtdm_Complexity  \\\n",
      "0                     1000000.0                        0.0   \n",
      "1                     1000000.0                        0.0   \n",
      "2                     1000000.0                        0.0   \n",
      "3                     1000000.0                        0.0   \n",
      "4                     1000000.0                        0.0   \n",
      "...                         ...                        ...   \n",
      "2646                  1000000.0                        0.0   \n",
      "2647                  1000000.0                        0.0   \n",
      "2648                  1000000.0                        0.0   \n",
      "2649                  1000000.0                        0.0   \n",
      "2650                  1000000.0                        0.0   \n",
      "\n",
      "      original_ngtdm_Contrast  original_ngtdm_Strength  \n",
      "0                         0.0                      0.0  \n",
      "1                         0.0                      0.0  \n",
      "2                         0.0                      0.0  \n",
      "3                         0.0                      0.0  \n",
      "4                         0.0                      0.0  \n",
      "...                       ...                      ...  \n",
      "2646                      0.0                      0.0  \n",
      "2647                      0.0                      0.0  \n",
      "2648                      0.0                      0.0  \n",
      "2649                      0.0                      0.0  \n",
      "2650                      0.0                      0.0  \n",
      "\n",
      "[2651 rows x 115 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Campião\\AppData\\Local\\Temp\\ipykernel_21396\\2713992272.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  outliers_df[coluna] = outliers.astype(int)\n",
      "C:\\Users\\Campião\\AppData\\Local\\Temp\\ipykernel_21396\\2713992272.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  outliers_df[coluna] = outliers.astype(int)\n",
      "C:\\Users\\Campião\\AppData\\Local\\Temp\\ipykernel_21396\\2713992272.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  outliers_df[coluna] = outliers.astype(int)\n",
      "C:\\Users\\Campião\\AppData\\Local\\Temp\\ipykernel_21396\\2713992272.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  outliers_df[coluna] = outliers.astype(int)\n",
      "C:\\Users\\Campião\\AppData\\Local\\Temp\\ipykernel_21396\\2713992272.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  outliers_df[coluna] = outliers.astype(int)\n",
      "C:\\Users\\Campião\\AppData\\Local\\Temp\\ipykernel_21396\\2713992272.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  outliers_df[coluna] = outliers.astype(int)\n",
      "C:\\Users\\Campião\\AppData\\Local\\Temp\\ipykernel_21396\\2713992272.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  outliers_df[coluna] = outliers.astype(int)\n",
      "C:\\Users\\Campião\\AppData\\Local\\Temp\\ipykernel_21396\\2713992272.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  outliers_df[coluna] = outliers.astype(int)\n",
      "C:\\Users\\Campião\\AppData\\Local\\Temp\\ipykernel_21396\\2713992272.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  outliers_df[coluna] = outliers.astype(int)\n",
      "C:\\Users\\Campião\\AppData\\Local\\Temp\\ipykernel_21396\\2713992272.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  outliers_df[coluna] = outliers.astype(int)\n",
      "C:\\Users\\Campião\\AppData\\Local\\Temp\\ipykernel_21396\\2713992272.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  outliers_df[coluna] = outliers.astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      subtlety  internalStructure  calcification  sphericity  margin  \\\n",
      "0          NaN                NaN            NaN         NaN     NaN   \n",
      "1          NaN                NaN            NaN         NaN     NaN   \n",
      "2          0.0                0.0            0.0         0.0     0.0   \n",
      "3          NaN                NaN            NaN         NaN     NaN   \n",
      "4          NaN                NaN            NaN         NaN     NaN   \n",
      "...        ...                ...            ...         ...     ...   \n",
      "2646       NaN                NaN            NaN         NaN     NaN   \n",
      "2647       NaN                NaN            NaN         NaN     NaN   \n",
      "2648       NaN                NaN            NaN         NaN     NaN   \n",
      "2649       0.0                0.0            0.0         0.0     0.0   \n",
      "2650       0.0                0.0            1.0         0.0     0.0   \n",
      "\n",
      "      lobulation  spiculation  texture  original_shape_Elongation  \\\n",
      "0            NaN          NaN      NaN                        NaN   \n",
      "1            NaN          NaN      NaN                        NaN   \n",
      "2            0.0          0.0      0.0                        0.0   \n",
      "3            NaN          NaN      NaN                        NaN   \n",
      "4            NaN          NaN      NaN                        NaN   \n",
      "...          ...          ...      ...                        ...   \n",
      "2646         NaN          NaN      NaN                        NaN   \n",
      "2647         NaN          NaN      NaN                        NaN   \n",
      "2648         NaN          NaN      NaN                        NaN   \n",
      "2649         0.0          0.0      0.0                        0.0   \n",
      "2650         1.0          1.0      0.0                        0.0   \n",
      "\n",
      "      original_shape_Flatness  ...  \\\n",
      "0                         NaN  ...   \n",
      "1                         NaN  ...   \n",
      "2                         0.0  ...   \n",
      "3                         NaN  ...   \n",
      "4                         NaN  ...   \n",
      "...                       ...  ...   \n",
      "2646                      NaN  ...   \n",
      "2647                      NaN  ...   \n",
      "2648                      NaN  ...   \n",
      "2649                      0.0  ...   \n",
      "2650                      0.0  ...   \n",
      "\n",
      "      original_glszm_SmallAreaHighGrayLevelEmphasis  \\\n",
      "0                                               NaN   \n",
      "1                                               NaN   \n",
      "2                                               0.0   \n",
      "3                                               NaN   \n",
      "4                                               NaN   \n",
      "...                                             ...   \n",
      "2646                                            NaN   \n",
      "2647                                            NaN   \n",
      "2648                                            NaN   \n",
      "2649                                            0.0   \n",
      "2650                                            1.0   \n",
      "\n",
      "      original_glszm_SmallAreaLowGrayLevelEmphasis  \\\n",
      "0                                              NaN   \n",
      "1                                              NaN   \n",
      "2                                              0.0   \n",
      "3                                              NaN   \n",
      "4                                              NaN   \n",
      "...                                            ...   \n",
      "2646                                           NaN   \n",
      "2647                                           NaN   \n",
      "2648                                           NaN   \n",
      "2649                                           0.0   \n",
      "2650                                           1.0   \n",
      "\n",
      "      original_glszm_ZoneEntropy  original_glszm_ZonePercentage  \\\n",
      "0                            NaN                            NaN   \n",
      "1                            NaN                            NaN   \n",
      "2                            0.0                            0.0   \n",
      "3                            NaN                            NaN   \n",
      "4                            NaN                            NaN   \n",
      "...                          ...                            ...   \n",
      "2646                         NaN                            NaN   \n",
      "2647                         NaN                            NaN   \n",
      "2648                         NaN                            NaN   \n",
      "2649                         0.0                            0.0   \n",
      "2650                         1.0                            0.0   \n",
      "\n",
      "      original_glszm_ZoneVariance  original_ngtdm_Busyness  \\\n",
      "0                             NaN                      NaN   \n",
      "1                             NaN                      NaN   \n",
      "2                             0.0                      0.0   \n",
      "3                             NaN                      NaN   \n",
      "4                             NaN                      NaN   \n",
      "...                           ...                      ...   \n",
      "2646                          NaN                      NaN   \n",
      "2647                          NaN                      NaN   \n",
      "2648                          NaN                      NaN   \n",
      "2649                          0.0                      0.0   \n",
      "2650                          1.0                      0.0   \n",
      "\n",
      "      original_ngtdm_Coarseness  original_ngtdm_Complexity  \\\n",
      "0                           NaN                        NaN   \n",
      "1                           NaN                        NaN   \n",
      "2                           0.0                        0.0   \n",
      "3                           NaN                        NaN   \n",
      "4                           NaN                        NaN   \n",
      "...                         ...                        ...   \n",
      "2646                        NaN                        NaN   \n",
      "2647                        NaN                        NaN   \n",
      "2648                        NaN                        NaN   \n",
      "2649                        0.0                        0.0   \n",
      "2650                        0.0                        0.0   \n",
      "\n",
      "      original_ngtdm_Contrast  original_ngtdm_Strength  \n",
      "0                         NaN                      NaN  \n",
      "1                         NaN                      NaN  \n",
      "2                         0.0                      0.0  \n",
      "3                         NaN                      NaN  \n",
      "4                         NaN                      NaN  \n",
      "...                       ...                      ...  \n",
      "2646                      NaN                      NaN  \n",
      "2647                      NaN                      NaN  \n",
      "2648                      NaN                      NaN  \n",
      "2649                      0.0                      0.0  \n",
      "2650                      0.0                      0.0  \n",
      "\n",
      "[2651 rows x 115 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Campião\\AppData\\Local\\Temp\\ipykernel_21396\\2713992272.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  outliers_df[coluna] = outliers.astype(int)\n",
      "C:\\Users\\Campião\\AppData\\Local\\Temp\\ipykernel_21396\\2713992272.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  outliers_df[coluna] = outliers.astype(int)\n",
      "C:\\Users\\Campião\\AppData\\Local\\Temp\\ipykernel_21396\\2713992272.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  outliers_df[coluna] = outliers.astype(int)\n",
      "C:\\Users\\Campião\\AppData\\Local\\Temp\\ipykernel_21396\\2713992272.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  outliers_df[coluna] = outliers.astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Suponha que 'dados' seja o DataFrame com seus dados e 'labels' seja a coluna de labels.\n",
    "# Suponha que 'scaled' seja seu DataFrame já dimensionado.\n",
    "\n",
    "# Separe a população sem câncer\n",
    "populacao_sem_cancer = []\n",
    "\n",
    "for i in range(len(values)):\n",
    "    if values[i] == 0:\n",
    "        populacao_sem_cancer.append(i)\n",
    "\n",
    "# Crie um DataFrame para rastrear os outliers em relação a cada variável\n",
    "outliers_df = pd.DataFrame(index=X.index)\n",
    "\n",
    "# Itere sobre cada coluna do DataFrame 'scaled'\n",
    "for coluna in X.columns:\n",
    "    data_plot1 = X[X.index.isin(populacao_sem_cancer)]\n",
    "    data_plot = data_plot1[coluna]\n",
    "    \n",
    "    # Crie um gráfico de box plot para a variável\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    data_plot.plot.box(vert=False)\n",
    "    plt.title(f'Box Plot de Outliers em {coluna}')\n",
    "    plt.xlabel('Valores')\n",
    "    plt.show()\n",
    "\n",
    "    # Identifique os outliers para a variável\n",
    "    limite = 3  # Defina o limite de outlier como desejar\n",
    "    z_scores = np.abs((data_plot - data_plot.mean()) / data_plot.std())\n",
    "    outliers = z_scores > limite\n",
    "    outliers_df[coluna] = outliers.astype(int)\n",
    "\n",
    "print(outliers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 1.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 6.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 3.0, 3.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 6.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 2.0, 4.0, 0.0, 2.0, 1.0, 4.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 2.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 1.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 1.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 5.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 8.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 9.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 5.0, 0.0, 0.0, 0.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 6.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 8.0, 0.0, 5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 7.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 9.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0]\n",
      "2636\n",
      "      subtlety  internalStructure  calcification  sphericity  margin  \\\n",
      "0            4                  1              6           4       4   \n",
      "1            5                  1              6           4       2   \n",
      "2            4                  1              5           5       5   \n",
      "3            5                  1              4           4       2   \n",
      "4            3                  1              6           5       5   \n",
      "...        ...                ...            ...         ...     ...   \n",
      "2645         3                  1              6           4       4   \n",
      "2646         4                  1              6           4       4   \n",
      "2647         1                  1              6           4       1   \n",
      "2648         2                  1              6           4       3   \n",
      "2649         5                  1              6           4       5   \n",
      "\n",
      "      lobulation  spiculation  texture  original_shape_Elongation  \\\n",
      "0              2            2        5                   0.848594   \n",
      "1              4            1        5                   0.845360   \n",
      "2              1            1        5                   0.879310   \n",
      "3              4            3        5                   0.956858   \n",
      "4              5            5        5                   0.779886   \n",
      "...          ...          ...      ...                        ...   \n",
      "2645           1            1        1                   0.761592   \n",
      "2646           2            2        5                   0.793847   \n",
      "2647           1            1        1                   0.754255   \n",
      "2648           1            1        5                   0.564212   \n",
      "2649           1            1        5                   0.453474   \n",
      "\n",
      "      original_shape_Flatness  ...  \\\n",
      "0                    0.219031  ...   \n",
      "1                    0.215045  ...   \n",
      "2                    0.289526  ...   \n",
      "3                    0.216692  ...   \n",
      "4                    0.595806  ...   \n",
      "...                       ...  ...   \n",
      "2645                 0.244086  ...   \n",
      "2646                 0.375133  ...   \n",
      "2647                 0.687954  ...   \n",
      "2648                 0.185778  ...   \n",
      "2649                 0.247844  ...   \n",
      "\n",
      "      original_glszm_SmallAreaHighGrayLevelEmphasis  \\\n",
      "0                                      2.761356e-07   \n",
      "1                                      3.299153e-07   \n",
      "2                                      8.650519e-04   \n",
      "3                                      6.666667e-01   \n",
      "4                                      3.684042e-06   \n",
      "...                                             ...   \n",
      "2645                                   1.983733e-04   \n",
      "2646                                   9.467456e-06   \n",
      "2647                                   2.576463e-06   \n",
      "2648                                   2.799474e-05   \n",
      "2649                                   1.686625e-04   \n",
      "\n",
      "      original_glszm_SmallAreaLowGrayLevelEmphasis  \\\n",
      "0                                     2.761356e-07   \n",
      "1                                     3.299153e-07   \n",
      "2                                     8.650519e-04   \n",
      "3                                     6.666667e-01   \n",
      "4                                     3.684042e-06   \n",
      "...                                            ...   \n",
      "2645                                  1.983733e-04   \n",
      "2646                                  9.467456e-06   \n",
      "2647                                  2.576463e-06   \n",
      "2648                                  2.799474e-05   \n",
      "2649                                  1.686625e-04   \n",
      "\n",
      "      original_glszm_ZoneEntropy  original_glszm_ZonePercentage  \\\n",
      "0                  -3.203427e-16                       0.000525   \n",
      "1                  -3.203427e-16                       0.000574   \n",
      "2                  -3.203427e-16                       0.029412   \n",
      "3                   9.182958e-01                       0.000823   \n",
      "4                  -3.203427e-16                       0.001919   \n",
      "...                          ...                            ...   \n",
      "2645               -3.203427e-16                       0.014085   \n",
      "2646               -3.203427e-16                       0.003077   \n",
      "2647               -3.203427e-16                       0.001605   \n",
      "2648               -3.203427e-16                       0.005291   \n",
      "2649               -3.203427e-16                       0.012987   \n",
      "\n",
      "      original_glszm_ZoneVariance  original_ngtdm_Busyness  \\\n",
      "0                    0.000000e+00                      0.0   \n",
      "1                    0.000000e+00                      0.0   \n",
      "2                    0.000000e+00                      0.0   \n",
      "3                    2.949211e+06                      0.0   \n",
      "4                    0.000000e+00                      0.0   \n",
      "...                           ...                      ...   \n",
      "2645                 0.000000e+00                      0.0   \n",
      "2646                 0.000000e+00                      0.0   \n",
      "2647                 0.000000e+00                      0.0   \n",
      "2648                 0.000000e+00                      0.0   \n",
      "2649                 0.000000e+00                      0.0   \n",
      "\n",
      "      original_ngtdm_Coarseness  original_ngtdm_Complexity  \\\n",
      "0                     1000000.0                        0.0   \n",
      "1                     1000000.0                        0.0   \n",
      "2                     1000000.0                        0.0   \n",
      "3                     1000000.0                        0.0   \n",
      "4                     1000000.0                        0.0   \n",
      "...                         ...                        ...   \n",
      "2645                  1000000.0                        0.0   \n",
      "2646                  1000000.0                        0.0   \n",
      "2647                  1000000.0                        0.0   \n",
      "2648                  1000000.0                        0.0   \n",
      "2649                  1000000.0                        0.0   \n",
      "\n",
      "      original_ngtdm_Contrast  original_ngtdm_Strength  \n",
      "0                         0.0                      0.0  \n",
      "1                         0.0                      0.0  \n",
      "2                         0.0                      0.0  \n",
      "3                         0.0                      0.0  \n",
      "4                         0.0                      0.0  \n",
      "...                       ...                      ...  \n",
      "2645                      0.0                      0.0  \n",
      "2646                      0.0                      0.0  \n",
      "2647                      0.0                      0.0  \n",
      "2648                      0.0                      0.0  \n",
      "2649                      0.0                      0.0  \n",
      "\n",
      "[2636 rows x 115 columns]\n",
      "[1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0]\n",
      "[1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "outliers_df['Total'] = outliers_df.sum(axis=1)\n",
    "\n",
    "# Agora você tem a coluna 'Total' adicionada ao seu DataFrame com a soma de cada linha.\n",
    "\n",
    "indicetirar=[]\n",
    "outliers20=outliers_df['Total'].tolist()\n",
    "for i in range(len(outliers20)):\n",
    "    if outliers20[i]<=20:\n",
    "        indicetirar.append(i)\n",
    "\n",
    "\n",
    "X2=X.iloc[indicetirar]\n",
    "\n",
    "\n",
    "# Use list comprehension para criar uma nova lista sem os valores nos índices especificados\n",
    "y_alterado = [valor for i, valor in enumerate(values) if i in indicetirar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2862393a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 1966, 1: 670})\n"
     ]
    }
   ],
   "source": [
    "oversample = SMOTE()\n",
    "counter = Counter(y_alterado)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95842395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 1966, 0: 1966})\n"
     ]
    }
   ],
   "source": [
    "X2, y2 = oversample.fit_resample(X2, y_alterado)\n",
    "print(Counter(y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_continuous = scaler.fit_transform(X2)\n",
    "\n",
    "scaled = pd.DataFrame(X_continuous, columns=X2.columns)\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled, y2, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após efetuar novamente o Standard-Scalling, decidimos voltar a executar os três algoritmos com o novo conjunto de labels equilibradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=3, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=3, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=3, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=3, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=3, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=3, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=3, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=3, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=3, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=3, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.6s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Campião\\LIACD\\A3-S1\\LabIACD\\LungCancer\\LabIACDreal.ipynb Cell 52\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Campi%C3%A3o/LIACD/A3-S1/LabIACD/LungCancer/LabIACDreal.ipynb#Y440sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m param_grid\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m:[\u001b[39m3\u001b[39m,\u001b[39m5\u001b[39m,\u001b[39m10\u001b[39m,\u001b[39mNone\u001b[39;00m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Campi%C3%A3o/LIACD/A3-S1/LabIACD/LungCancer/LabIACDreal.ipynb#Y440sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m:[\u001b[39m10\u001b[39m,\u001b[39m100\u001b[39m,\u001b[39m200\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Campi%C3%A3o/LIACD/A3-S1/LabIACD/LungCancer/LabIACDreal.ipynb#Y440sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mmin_samples_leaf\u001b[39m\u001b[39m'\u001b[39m:[\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Campi%C3%A3o/LIACD/A3-S1/LabIACD/LungCancer/LabIACDreal.ipynb#Y440sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mmin_samples_split\u001b[39m\u001b[39m'\u001b[39m:[\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Campi%C3%A3o/LIACD/A3-S1/LabIACD/LungCancer/LabIACDreal.ipynb#Y440sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m            }\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Campi%C3%A3o/LIACD/A3-S1/LabIACD/LungCancer/LabIACDreal.ipynb#Y440sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m grid \u001b[39m=\u001b[39m GridSearchCV(RandomForestClassifier(),param_grid,refit\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m);\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Campi%C3%A3o/LIACD/A3-S1/LabIACD/LungCancer/LabIACDreal.ipynb#Y440sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m grid\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Campi%C3%A3o/LIACD/A3-S1/LabIACD/LungCancer/LabIACDreal.ipynb#Y440sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(grid\u001b[39m.\u001b[39mbest_estimator_)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Campi%C3%A3o/LIACD/A3-S1/LabIACD/LungCancer/LabIACDreal.ipynb#Y440sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m grid_predictions \u001b[39m=\u001b[39m grid\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    475\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    476\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    477\u001b[0m )(\n\u001b[0;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    479\u001b[0m         t,\n\u001b[0;32m    480\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    481\u001b[0m         X,\n\u001b[0;32m    482\u001b[0m         y,\n\u001b[0;32m    483\u001b[0m         sample_weight,\n\u001b[0;32m    484\u001b[0m         i,\n\u001b[0;32m    485\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    486\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    487\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    488\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    489\u001b[0m     )\n\u001b[0;32m    490\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    491\u001b[0m )\n\u001b[0;32m    493\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    182\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 184\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\tree\\_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    860\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    890\u001b[0m         X,\n\u001b[0;32m    891\u001b[0m         y,\n\u001b[0;32m    892\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    893\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\tree\\_classes.py:224\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m    223\u001b[0m \u001b[39mif\u001b[39;00m is_classification:\n\u001b[1;32m--> 224\u001b[0m     check_classification_targets(y)\n\u001b[0;32m    225\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcopy(y)\n\u001b[0;32m    227\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\multiclass.py:210\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_classification_targets\u001b[39m(y):\n\u001b[0;32m    199\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Ensure that target y is of a non-regression type.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \n\u001b[0;32m    201\u001b[0m \u001b[39m    Only the following target types (as defined in type_of_target) are allowed:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[39m        Target values.\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m     y_type \u001b[39m=\u001b[39m type_of_target(y, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    211\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\n\u001b[0;32m    212\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    213\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultilabel-sequences\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    217\u001b[0m     ]:\n\u001b[0;32m    218\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\multiclass.py:386\u001b[0m, in \u001b[0;36mtype_of_target\u001b[1;34m(y, input_name)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[39m# Check multiclass\u001b[39;00m\n\u001b[0;32m    385\u001b[0m first_row \u001b[39m=\u001b[39m y[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m issparse(y) \u001b[39melse\u001b[39;00m y\u001b[39m.\u001b[39mgetrow(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mdata\n\u001b[1;32m--> 386\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39;49munique_values(y)\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m (y\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(first_row) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m    387\u001b[0m     \u001b[39m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[39;00m\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m suffix\n\u001b[0;32m    389\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\_array_api.py:84\u001b[0m, in \u001b[0;36m_NumPyApiWrapper.unique_values\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munique_values\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 84\u001b[0m     \u001b[39mreturn\u001b[39;00m numpy\u001b[39m.\u001b[39;49munique(x)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    272\u001b[0m ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(ar)\n\u001b[0;32m    273\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0;32m    275\u001b[0m                     equal_nan\u001b[39m=\u001b[39;49mequal_nan)\n\u001b[0;32m    276\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    278\u001b[0m \u001b[39m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\lib\\arraysetops.py:355\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[0;32m    352\u001b[0m     mask[\u001b[39m1\u001b[39m:] \u001b[39m=\u001b[39m aux[\u001b[39m1\u001b[39m:] \u001b[39m!=\u001b[39m aux[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    354\u001b[0m ret \u001b[39m=\u001b[39m (aux[mask],)\n\u001b[1;32m--> 355\u001b[0m \u001b[39mif\u001b[39;00m return_index:\n\u001b[0;32m    356\u001b[0m     ret \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (perm[mask],)\n\u001b[0;32m    357\u001b[0m \u001b[39mif\u001b[39;00m return_inverse:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid={'max_depth':[3,5,10,None],\n",
    "              'n_estimators':[10,100,200],\n",
    "              'min_samples_leaf':[1,2,3],\n",
    "              'min_samples_split':[1,2,3]\n",
    "           }\n",
    "\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(),param_grid,refit=True,verbose=1);\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "grid_predictions = grid.predict(X_test)\n",
    "print(classification_report(y_test,grid_predictions))\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, grid_predictions)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot();\n",
    "\n",
    "accuracy = accuracy_score(y_test, grid_predictions)\n",
    "precision = precision_score(y_test, grid_predictions)\n",
    "recall = recall_score(y_test, grid_predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1, gamma=0.1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87       596\n",
      "           1       0.86      0.88      0.87       593\n",
      "\n",
      "    accuracy                           0.87      1189\n",
      "   macro avg       0.87      0.87      0.87      1189\n",
      "weighted avg       0.87      0.87      0.87      1189\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAGwCAYAAACuFMx9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+wUlEQVR4nO3de3wU5fn///fmTA4bCJgskRBF5BA5KVrYVhElEiA/lZLPx6oI0SJ+xYAKgkjLGQU/eEIsolUL0kI9VWiNiASUoBKoRBEETAuiiZJNVCQh0Zx25/cHZtsV0Cy7yZKd1/PxmEeZmfueudKmXNzXfc+MxTAMQwAAIGiFBDoAAADQvEj2AAAEOZI9AABBjmQPAECQI9kDABDkSPYAAAQ5kj0AAEEuLNAB+MLlcunw4cOKi4uTxWIJdDgAAC8ZhqFjx44pOTlZISHNN/6sqalRXV2dz9eJiIhQVFSUHyJqWa062R8+fFgpKSmBDgMA4KOSkhJ16tSpWa5dU1Ojc1Nj5Sh3+nwtm82mQ4cOtbqE36qTfVxcnCRp306b4mKZkUBwyu53aaBDAJpNg1GvrbVr3X+fN4e6ujo5yp36vPAcWeNOP1dUHnMptf9nqqurI9m3pMbSfVxsiE//AwJnsjBLRKBDAJpdS0zFxsZZFBt3+vdxqfVOF7fqZA8AQFM5DZecPnwNxmm4/BdMCyPZAwBMwSVDLp1+tvelb6BR+wYAIMgxsgcAmIJLLvlSiPetd2CR7AEApuA0DDmN0y/F+9I30CjjAwAQ5BjZAwBMwcwL9Ej2AABTcMmQ06TJnjI+AABBjpE9AMAUKOMDABDkWI0PAAD8au7cubJYLB5bjx493OdramqUk5Oj9u3bKzY2VllZWSorK/O4RnFxsTIzMxUdHa3ExERNmzZNDQ0NXsfCyB4AYAquHzZf+nvrggsu0KZNm9z7YWH/SbuTJ0/W66+/rpdfflnx8fGaOHGiRo0apffee0+S5HQ6lZmZKZvNpm3btqm0tFRjx45VeHi4Fi5c6FUcJHsAgCk4fVyN39i3srLS43hkZKQiIyNP2icsLEw2m+2E4xUVFXruuee0Zs0aXXnllZKkFStWqGfPntq+fbsGDhyojRs3at++fdq0aZOSkpLUr18/LViwQNOnT9fcuXMVEdH0L2JSxgcAmILT8H2TpJSUFMXHx7u3RYsWnfKe//73v5WcnKwuXbpo9OjRKi4uliQVFhaqvr5e6enp7rY9evRQ586dVVBQIEkqKChQ7969lZSU5G6TkZGhyspK7d2716ufnZE9AABeKCkpkdVqde+falQ/YMAArVy5Ut27d1dpaanmzZunyy67TB9//LEcDociIiLUtm1bjz5JSUlyOBySJIfD4ZHoG883nvMGyR4AYAr+mrO3Wq0eyf5Uhg8f7v5znz59NGDAAKWmpuqll15SmzZtfIjEe5TxAQCm4JJFTh82lyw+3b9t27bq1q2bDhw4IJvNprq6Oh09etSjTVlZmXuO32aznbA6v3H/ZOsAfgrJHgCAFlBVVaWDBw+qY8eO6t+/v8LDw7V582b3+aKiIhUXF8tut0uS7Ha79uzZo/LycnebvLw8Wa1WpaWleXVvyvgAAFNwGcc3X/p7Y+rUqbr66quVmpqqw4cPa86cOQoNDdUNN9yg+Ph4jRs3TlOmTFFCQoKsVqsmTZoku92ugQMHSpKGDh2qtLQ0jRkzRosXL5bD4dDMmTOVk5NzynUCp0KyBwCYQmM53pf+3vjiiy90ww036JtvvtFZZ52lSy+9VNu3b9dZZ50lSXrssccUEhKirKws1dbWKiMjQ08++aS7f2hoqHJzczVhwgTZ7XbFxMQoOztb8+fP9zp2i2G03vf/VVZWKj4+XiWfJMsax4wEgtP/dh0c6BCAZtNg1OmtmpdUUVHRpEVvp6MxV+zYa1OsD7mi6phLAy5wNGuszYWRPQDAFFp6ZH8mIdkDAEzBZVjkMk4/YfvSN9CofQMAEOQY2QMATIEyPgAAQc6pEDl9KGg7/RhLSyPZAwBMwfBxzt5gzh4AAJypGNkDAEyBOXsAAIKc0wiR0/Bhzr7VvoKOMj4AAEGPkT0AwBRcssjlwxjXpdY7tCfZAwBMwcxz9pTxAQAIcozsAQCm4PsCPcr4AACc0Y7P2fvwIRzK+AAA4EzFyB4AYAouH9+Nz2p8AADOcMzZAwAQ5FwKMe1z9szZAwAQ5BjZAwBMwWlY5PThM7W+9A00kj0AwBScPi7Qc1LGBwAAZypG9gAAU3AZIXL5sBrfxWp8AADObJTxAQBA0GJkDwAwBZd8W1Hv8l8oLY5kDwAwBd9fqtN6i+GtN3IAANAkjOwBAKbg+7vxW+/4uPVGDgCAFxq/Z+/LdroefPBBWSwW3X333e5jgwcPlsVi8dhuv/12j37FxcXKzMxUdHS0EhMTNW3aNDU0NHh9f0b2AABTCNTI/v3339fTTz+tPn36nHBu/Pjxmj9/vns/Ojr6P/dzOpWZmSmbzaZt27aptLRUY8eOVXh4uBYuXOhVDIzsAQBoJlVVVRo9erSeeeYZtWvX7oTz0dHRstls7s1qtbrPbdy4Ufv27dNf/vIX9evXT8OHD9eCBQu0bNky1dXVeRUHyR4AYAqNL9XxZZOkyspKj622tvaU98zJyVFmZqbS09NPen716tXq0KGDevXqpRkzZui7775znysoKFDv3r2VlJTkPpaRkaHKykrt3bvXq5+dMj4AwBRchkUuX56z/6FvSkqKx/E5c+Zo7ty5J7R/4YUX9MEHH+j9998/6fVuvPFGpaamKjk5Wbt379b06dNVVFSkV199VZLkcDg8Er0k977D4fAqdpI9AABeKCkp8Si3R0ZGnrTNXXfdpby8PEVFRZ30Orfddpv7z71791bHjh01ZMgQHTx4UOedd55fY6aMDwAwBZePJfzGl+pYrVaP7WTJvrCwUOXl5brooosUFhamsLAw5efna+nSpQoLC5PT6Tyhz4ABAyRJBw4ckCTZbDaVlZV5tGnct9lsXv3sjOwBAKbg+1fvmt53yJAh2rNnj8exW265RT169ND06dMVGhp6Qp9du3ZJkjp27ChJstvteuCBB1ReXq7ExERJUl5enqxWq9LS0ryKnWQPAICfxcXFqVevXh7HYmJi1L59e/Xq1UsHDx7UmjVrNGLECLVv3167d+/W5MmTNWjQIPcjekOHDlVaWprGjBmjxYsXy+FwaObMmcrJyTlpNeGnkOwBAKbglEVOH16M40vfH4uIiNCmTZu0ZMkSVVdXKyUlRVlZWZo5c6a7TWhoqHJzczVhwgTZ7XbFxMQoOzvb47n8piLZAwBMoSXL+CezZcsW959TUlKUn5//s31SU1O1fv16n+4rsUAPAICgx8geAGAKTvlWij9x/XzrQbIHAJhCoMv4gUSyBwCYAp+4BQAAQYuRPQDAFAwfv0lv+PHRu5ZGsgcAmAJlfAAAELQY2QMATMFfn7htjUj2AABTaPx6nS/9W6vWGzkAAGgSRvYAAFOgjA8AQJBzKUQuHwravvQNtNYbOQAAaBJG9gAAU3AaFjl9KMX70jfQSPYAAFNgzh4AgCBn+PjVO4M36AEAgDMVI3sAgCk4ZZHTh4/Z+NI30Ej2AABTcBm+zbu7DD8G08Io4wMAEOQY2Zvci4900kuPdfI4lnze93oi/yNJ0sa/JOrddR306cfR+r4qTKv2vq+YeKe7bXlJpF5ecrY+3mbV0fIItbPVadCvv1bWnV8qPKIV/zMYQS0kxNDou77QlSO/Ubuz6nSkLEJ5fztLf/1DsnSSUu3E+w8p88ZyPb2gs9at6NjyAcMvXD4u0POlb6CR7KGU7t9pzl/3u/dDw/6TpOtqQtRv8FH1G3xUqx/sfELfLw9EyTCk//fgIdnOqVFJUbSW33uuar8PUfas4haJH/DW/95+WJmjy/XItC76/F/R6tanSpP/71NVHwvVP563ebT95dAj6tGvSl87wgMULfzFJYtcPsy7+9I30M6If6YsW7ZM55xzjqKiojRgwAD985//DHRIphIaaqhdYr17syY0uM/9f7c6NGriYXW7qOqkfS+8okITH/1U/S6vkC21VpcM/VbX/L9SbX8joaXCB7zW86Iqbd/UTu+/3U7lX0bq3Tfa64N349W9r+fvefukOk2Y85kWTz5PzobW+xc9EPBk/+KLL2rKlCmaM2eOPvjgA/Xt21cZGRkqLy8PdGimUXooSrf2v0gTftlPSyZ21VdfRvh0ve+OhSqubcPPNwQCZP8Hser3ywqdfe73kqRze1TrgouPaWd+W3cbi8XQ1EcO6pVnklX87+gARQp/anyDni9baxXwMv6jjz6q8ePH65ZbbpEkPfXUU3r99df1pz/9Sffdd1+Aowt+519YpYmPHVRylxp9Wx6ulx/rpJmjLtCSzR+pTazL6+uVHorUGytsGjuTEj7OXC8tT1Z0rFN/zNstl9OikFBDzz/SSW//vYO7zf/eflgup/T3lUkBjBT+xJx9gNTV1amwsFAzZsxwHwsJCVF6eroKCgpOaF9bW6va2lr3fmVlZYvEGcwuuvKo+8/npEndLqzS7QMv1HuvtVf6DV95da1vSsN1/009Zc88oqtGU5nBmWtQ5hFdcc03Wnx3V33+7zbq0rNa/29WsY6URWjTq2epa69qXXtzmSZd3UsnW7AHtDYBTfZff/21nE6nkpI8/+WclJSkTz755IT2ixYt0rx581oqPFOKiXeqY5caOT6L8qrfEUe45lyXpu4XH9Ptiz9tpugA/xh3X7Feerqj8nPbS5I+K4pW4tl1um7CYW169Sz1uqRSbdvXa9W7H7r7hIZJt/6uWCNvcejmQRcGKnT4wCUf343fiv/hF/AyvjdmzJihKVOmuPcrKyuVkpISwIiCz/fVISr7LErtRn3d5D7flB5P9F36VCvn0YMKab2VLphEZBuXDJfnX9wul2T54Xd389oO+vC9eI/z96/8RG+t66CNL5/VUmHCzwwfV+MbJPvT06FDB4WGhqqsrMzjeFlZmWw22wntIyMjFRkZ2VLhmcLzCzrr4vRvdVanOh0pC9eLj3RSSKihS0ceT/bflofr6Ffhcnx2/L/3zz+JVptYpzok1yqunVPflIZr9v+m6axOdcqe+bkqv/nP40ntEusD8jMBP2fH5ra6/o4vVX44Qp//K1pdL6jWqN86tPGV44n82NFwHTvq+aids8Gib78K15eH2gQiZPiBmb96F9AxWEREhPr376/Nmze7j7lcLm3evFl2uz2AkZnHN6URemzi+Zp0eV89cvv5imvXoEX/+Fjx7Y+vpt/45yRNzeij5feeJ0malXWBpmb00ft5xx+t++idtnJ81kZ73o3XbZf0160X/WcDzlTL552jdze0V878z/THvI9064xirf9rolY92unnOwOn4cEHH5TFYtHdd9/tPlZTU6OcnBy1b99esbGxysrKOmHwW1xcrMzMTEVHRysxMVHTpk1TQ4P3TzsFvIw/ZcoUZWdn6+KLL9YvfvELLVmyRNXV1e7V+WheU5488JPnf3PPF/rNPV+c8vyV132lK6/zbiEfEGjfV4fq6QWpenpBapP7ME/f+gVqNf7777+vp59+Wn369PE4PnnyZL3++ut6+eWXFR8fr4kTJ2rUqFF67733JElOp1OZmZmy2Wzatm2bSktLNXbsWIWHh2vhwoVexRDwZP+b3/xGX331lWbPni2Hw6F+/fppw4YNJyzaAwDAF4Eo41dVVWn06NF65plndP/997uPV1RU6LnnntOaNWt05ZVXSpJWrFihnj17avv27Ro4cKA2btyoffv2adOmTUpKSlK/fv20YMECTZ8+XXPnzlVERNPfiXJGLKWaOHGiPv/8c9XW1mrHjh0aMGBAoEMCAOCkKisrPbb/fiT8x3JycpSZman09HSP44WFhaqvr/c43qNHD3Xu3Nn96HlBQYF69+7tMfjNyMhQZWWl9u7d61XMZ0SyBwCguTW+G9+XTZJSUlIUHx/v3hYtWnTS+73wwgv64IMPTnre4XAoIiJCbdu29TielJQkh8PhbnOyR9Mbz3kj4GV8AABagr/K+CUlJbJare7jJ3tKrKSkRHfddZfy8vIUFeXde0uaAyN7AAC8YLVaPbaTJfvCwkKVl5froosuUlhYmMLCwpSfn6+lS5cqLCxMSUlJqqur09GjRz36/fej5zab7aSPpjee8wbJHgBgCo0je1+2phoyZIj27NmjXbt2ubeLL75Yo0ePdv85PDzc49HzoqIiFRcXux89t9vt2rNnj8eH4fLy8mS1WpWWlubVz04ZHwBgCi25Gj8uLk69evXyOBYTE6P27du7j48bN05TpkxRQkKCrFarJk2aJLvdroEDB0qShg4dqrS0NI0ZM0aLFy+Ww+HQzJkzlZOT4/UL5kj2AAAEwGOPPaaQkBBlZWWptrZWGRkZevLJJ93nQ0NDlZubqwkTJshutysmJkbZ2dmaP3++1/ci2QMATCHQr8vdsmWLx35UVJSWLVumZcuWnbJPamqq1q9f79N9JZI9AMAkDPn25TrDf6G0OJI9AMAUAj2yDyRW4wMAEOQY2QMATMHMI3uSPQDAFMyc7CnjAwAQ5BjZAwBMwcwje5I9AMAUDMMiw4eE7UvfQKOMDwBAkGNkDwAwhf/+Jv3p9m+tSPYAAFMw85w9ZXwAAIIcI3sAgCmYeYEeyR4AYApmLuOT7AEApmDmkT1z9gAABDlG9gAAUzB8LOO35pE9yR4AYAqGJMPwrX9rRRkfAIAgx8geAGAKLllk4Q16AAAEL1bjAwCAoMXIHgBgCi7DIgsv1QEAIHgZho+r8VvxcnzK+AAABDlG9gAAUzDzAj2SPQDAFEj2AAAEOTMv0GPOHgCAIMfIHgBgCqzGBwAgyB1P9hYfNu/ut3z5cvXp00dWq1VWq1V2u11vvPGG+/zgwYNlsVg8tttvv93jGsXFxcrMzFR0dLQSExM1bdo0NTQ0eP2zM7IHAKAZdOrUSQ8++KDOP/98GYah559/Xtdee60+/PBDXXDBBZKk8ePHa/78+e4+0dHR7j87nU5lZmbKZrNp27ZtKi0t1dixYxUeHq6FCxd6FQvJHgBgCi29Gv/qq6/22H/ggQe0fPlybd++3Z3so6OjZbPZTtp/48aN2rdvnzZt2qSkpCT169dPCxYs0PTp0zV37lxFREQ0ORbK+AAAUzD8sElSZWWlx1ZbW/uz93Y6nXrhhRdUXV0tu93uPr569Wp16NBBvXr10owZM/Tdd9+5zxUUFKh3795KSkpyH8vIyFBlZaX27t3r1c/OyB4AAC+kpKR47M+ZM0dz5849ads9e/bIbrerpqZGsbGxWrt2rdLS0iRJN954o1JTU5WcnKzdu3dr+vTpKioq0quvvipJcjgcHoleknvf4XB4FTPJHgBgCv4q45eUlMhqtbqPR0ZGnrJP9+7dtWvXLlVUVOiVV15Rdna28vPzlZaWpttuu83drnfv3urYsaOGDBmigwcP6rzzzjvtOE+GMj4AwBz8VMdvXF3fuP1Uso+IiFDXrl3Vv39/LVq0SH379tXjjz9+0rYDBgyQJB04cECSZLPZVFZW5tGmcf9U8/ynQrIHAJiDT4/dWSQ/vEHP5XKdco5/165dkqSOHTtKkux2u/bs2aPy8nJ3m7y8PFmtVvdUQFNRxgcAoBnMmDFDw4cPV+fOnXXs2DGtWbNGW7Zs0ZtvvqmDBw9qzZo1GjFihNq3b6/du3dr8uTJGjRokPr06SNJGjp0qNLS0jRmzBgtXrxYDodDM2fOVE5Ozk9WE06GZA8AMIWWfoNeeXm5xo4dq9LSUsXHx6tPnz568803ddVVV6mkpESbNm3SkiVLVF1drZSUFGVlZWnmzJnu/qGhocrNzdWECRNkt9sVExOj7Oxsj+fym4pkDwAwhZZ+zv6555475bmUlBTl5+f/7DVSU1O1fv16r+57MszZAwAQ5BjZAwDMwddFdq34E7ckewCAKfDVOwAAELQY2QMAzOG/X3B/uv1bKZI9AMAUWno1/pmkScn+H//4R5MveM0115x2MAAAwP+alOxHjhzZpItZLBY5nU5f4gEAoPm04lK8L5qU7F0uV3PHAQBAszJzGd+n1fg1NTX+igMAgOblp6/etUZeJ3un06kFCxbo7LPPVmxsrD799FNJ0qxZs37y1YAAACAwvE72DzzwgFauXKnFixcrIiLCfbxXr1569tln/RocAAD+Y/HD1jp5nexXrVqlP/7xjxo9erRCQ0Pdx/v27atPPvnEr8EBAOA3lPGb7ssvv1TXrl1POO5yuVRfX++XoAAAgP94nezT0tL0zjvvnHD8lVde0YUXXuiXoAAA8DsTj+y9foPe7NmzlZ2drS+//FIul0uvvvqqioqKtGrVKuXm5jZHjAAA+M7EX73zemR/7bXX6rXXXtOmTZsUExOj2bNna//+/Xrttdd01VVXNUeMAADAB6f1bvzLLrtMeXl5/o4FAIBmY+ZP3J72h3B27typ/fv3Szo+j9+/f3+/BQUAgN/x1bum++KLL3TDDTfovffeU9u2bSVJR48e1S9/+Uu98MIL6tSpk79jBAAAPvB6zv7WW29VfX299u/fryNHjujIkSPav3+/XC6Xbr311uaIEQAA3zUu0PNla6W8Htnn5+dr27Zt6t69u/tY9+7d9cQTT+iyyy7za3AAAPiLxTi++dK/tfI62aekpJz05TlOp1PJycl+CQoAAL8z8Zy912X8hx56SJMmTdLOnTvdx3bu3Km77rpLDz/8sF+DAwAAvmvSyL5du3ayWP4zV1FdXa0BAwYoLOx494aGBoWFhem3v/2tRo4c2SyBAgDgExO/VKdJyX7JkiXNHAYAAM3MxGX8JiX77Ozs5o4DAAA0k9N+qY4k1dTUqK6uzuOY1Wr1KSAAAJqFiUf2Xi/Qq66u1sSJE5WYmKiYmBi1a9fOYwMA4Ixk4q/eeZ3s7733Xr311ltavny5IiMj9eyzz2revHlKTk7WqlWrmiNGAADgA6+T/WuvvaYnn3xSWVlZCgsL02WXXaaZM2dq4cKFWr16dXPECACA71r4DXrLly9Xnz59ZLVaZbVaZbfb9cYbb7jP19TUKCcnR+3bt1dsbKyysrJUVlbmcY3i4mJlZmYqOjpaiYmJmjZtmhoaGrz+0b1O9keOHFGXLl0kHZ+fP3LkiCTp0ksv1datW70OAACAltD4Bj1fNm906tRJDz74oAoLC7Vz505deeWVuvbaa7V3715J0uTJk/Xaa6/p5ZdfVn5+vg4fPqxRo0a5+zudTmVmZqqurk7btm3T888/r5UrV2r27Nle/+xeJ/suXbro0KFDkqQePXropZdeknR8xN/4YRwAAMzu6quv1ogRI3T++eerW7dueuCBBxQbG6vt27eroqJCzz33nB599FFdeeWV6t+/v1asWKFt27Zp+/btkqSNGzdq3759+stf/qJ+/fpp+PDhWrBggZYtW3bC4vif43Wyv+WWW/TRRx9Jku677z4tW7ZMUVFRmjx5sqZNm+bt5QAAaBl+WqBXWVnpsdXW1v7srZ1Op1544QVVV1fLbrersLBQ9fX1Sk9Pd7fp0aOHOnfurIKCAklSQUGBevfuraSkJHebjIwMVVZWuqsDTeX1o3eTJ092/zk9PV2ffPKJCgsL1bVrV/Xp08fbywEA0KqkpKR47M+ZM0dz5849ads9e/bIbrerpqZGsbGxWrt2rdLS0rRr1y5FREScUBFPSkqSw+GQJDkcDo9E33i+8Zw3fHrOXpJSU1OVmprq62UAAGhWFvn41bsf/rOkpMTjnTKRkZGn7NO9e3ft2rVLFRUVeuWVV5Sdna38/PzTD+I0NSnZL126tMkXvPPOO087GAAAznSNq+ubIiIiQl27dpUk9e/fX++//74ef/xx/eY3v1FdXZ2OHj3qMbovKyuTzWaTJNlsNv3zn//0uF7jav3GNk3VpGT/2GOPNeliFoslIMl+TI9LFGYJb/H7Ai3hzcPbAx0C0Gwqj7nUrlsL3ewM+BCOy+VSbW2t+vfvr/DwcG3evFlZWVmSpKKiIhUXF8tut0uS7Ha7HnjgAZWXlysxMVGSlJeXJ6vVqrS0NK/u26Rk37j6HgCAVquFX5c7Y8YMDR8+XJ07d9axY8e0Zs0abdmyRW+++abi4+M1btw4TZkyRQkJCbJarZo0aZLsdrsGDhwoSRo6dKjS0tI0ZswYLV68WA6HQzNnzlROTs5PTh2cjM9z9gAA4ETl5eUaO3asSktLFR8frz59+ujNN9/UVVddJel41TwkJERZWVmqra1VRkaGnnzySXf/0NBQ5ebmasKECbLb7YqJiVF2drbmz5/vdSwkewCAObTwyP655577yfNRUVFatmyZli1bdso2qampWr9+vXc3PgmSPQDAFE7nLXg/7t9aef1SHQAA0LowsgcAmAPfs/fOO++8o5tuukl2u11ffvmlJOnPf/6z3n33Xb8GBwCA3/A9+6b729/+poyMDLVp00Yffvih+53AFRUVWrhwod8DBAAAvvE62d9///166qmn9Mwzzyg8/D8vsvnVr36lDz74wK/BAQDgLy39idsziddz9kVFRRo0aNAJx+Pj43X06FF/xAQAgP+dAW/QCxSvR/Y2m00HDhw44fi7776rLl26+CUoAAD8jjn7phs/frzuuusu7dixQxaLRYcPH9bq1as1depUTZgwoTliBAAAPvC6jH/ffffJ5XJpyJAh+u677zRo0CBFRkZq6tSpmjRpUnPECACAz8z8Uh2vk73FYtHvf/97TZs2TQcOHFBVVZXS0tIUGxvbHPEBAOAfJn7O/rRfqhMREeH1J/YAAEDL8zrZX3HFFbJYTr0i8a233vIpIAAAmoWvj8+ZaWTfr18/j/36+nrt2rVLH3/8sbKzs/0VFwAA/kUZv+kee+yxkx6fO3euqqqqfA4IAAD4l9++enfTTTfpT3/6k78uBwCAf5n4OXu/ffWuoKBAUVFR/rocAAB+xaN3Xhg1apTHvmEYKi0t1c6dOzVr1iy/BQYAAPzD62QfHx/vsR8SEqLu3btr/vz5Gjp0qN8CAwAA/uFVsnc6nbrlllvUu3dvtWvXrrliAgDA/0y8Gt+rBXqhoaEaOnQoX7cDALQ6Zv7Erder8Xv16qVPP/20OWIBAADNwOtkf//992vq1KnKzc1VaWmpKisrPTYAAM5YJnzsTvJizn7+/Pm65557NGLECEnSNddc4/HaXMMwZLFY5HQ6/R8lAAC+MvGcfZOT/bx583T77bfr7bffbs54AACAnzU52RvG8X/SXH755c0WDAAAzYWX6jTRT33tDgCAMxpl/Kbp1q3bzyb8I0eO+BQQAADwL6+S/bx58054gx4AAK0BZfwmuv7665WYmNhcsQAA0HxMXMZv8nP2zNcDANA6NTnZN67GBwCgVWrh79kvWrRIl1xyieLi4pSYmKiRI0eqqKjIo83gwYNlsVg8tttvv92jTXFxsTIzMxUdHa3ExERNmzZNDQ0NXsXS5DK+y+Xy6sIAAJxJWnrOPj8/Xzk5ObrkkkvU0NCg3/3udxo6dKj27dunmJgYd7vx48dr/vz57v3o6Gj3n51OpzIzM2Wz2bRt2zaVlpZq7NixCg8P18KFC5sci9efuAUAoFXy05z9j18NHxkZqcjIyBOab9iwwWN/5cqVSkxMVGFhoQYNGuQ+Hh0dLZvNdtJbbty4Ufv27dOmTZuUlJSkfv36acGCBZo+fbrmzp2riIiIJoXu9bvxAQAws5SUFMXHx7u3RYsWNalfRUWFJCkhIcHj+OrVq9WhQwf16tVLM2bM0Hfffec+V1BQoN69eyspKcl9LCMjQ5WVldq7d2+TY2ZkDwAwBz+N7EtKSmS1Wt2HTzaq/zGXy6W7775bv/rVr9SrVy/38RtvvFGpqalKTk7W7t27NX36dBUVFenVV1+VJDkcDo9EL8m973A4mhw6yR4AYAr+mrO3Wq0eyb4pcnJy9PHHH+vdd9/1OH7bbbe5/9y7d2917NhRQ4YM0cGDB3XeeeedfrA/QhkfAIBmNHHiROXm5urtt99Wp06dfrLtgAEDJEkHDhyQJNlsNpWVlXm0adw/1Tz/yZDsAQDm0MKP3hmGoYkTJ2rt2rV66623dO655/5sn127dkmSOnbsKEmy2+3as2ePysvL3W3y8vJktVqVlpbW5Fgo4wMATKGlH73LycnRmjVr9Pe//11xcXHuOfb4+Hi1adNGBw8e1Jo1azRixAi1b99eu3fv1uTJkzVo0CD16dNHkjR06FClpaVpzJgxWrx4sRwOh2bOnKmcnJwmrRVoxMgeAIBmsHz5clVUVGjw4MHq2LGje3vxxRclSREREdq0aZOGDh2qHj166J577lFWVpZee+019zVCQ0OVm5ur0NBQ2e123XTTTRo7dqzHc/lNwcgeAGAOLfxu/J9782xKSory8/N/9jqpqalav369dzf/EZI9AMAc+BAOAAAIVozsAQCmYPlh86V/a0WyBwCYg4nL+CR7AIAptPSjd2cS5uwBAAhyjOwBAOZAGR8AABNoxQnbF5TxAQAIcozsAQCmYOYFeiR7AIA5mHjOnjI+AABBjpE9AMAUKOMDABDsKOMDAIBgxcgeAGAKlPEBAAh2Ji7jk+wBAOZg4mTPnD0AAEGOkT0AwBSYswcAINhRxgcAAMGKkT0AwBQshiGLcfrDc1/6BhrJHgBgDpTxAQBAsGJkDwAwBVbjAwAQ7CjjAwCAYMXIHgBgCpTxAQAIdpTxAQAIbo0je182byxatEiXXHKJ4uLilJiYqJEjR6qoqMijTU1NjXJyctS+fXvFxsYqKytLZWVlHm2Ki4uVmZmp6OhoJSYmatq0aWpoaPAqFpI9AADNID8/Xzk5Odq+fbvy8vJUX1+voUOHqrq62t1m8uTJeu211/Tyyy8rPz9fhw8f1qhRo9znnU6nMjMzVVdXp23btun555/XypUrNXv2bK9ioYwPADAHP5XxKysrPQ5HRkYqMjLyhOYbNmzw2F+5cqUSExNVWFioQYMGqaKiQs8995zWrFmjK6+8UpK0YsUK9ezZU9u3b9fAgQO1ceNG7du3T5s2bVJSUpL69eunBQsWaPr06Zo7d64iIiKaFDojewCAafijhJ+SkqL4+Hj3tmjRoibdu6KiQpKUkJAgSSosLFR9fb3S09PdbXr06KHOnTuroKBAklRQUKDevXsrKSnJ3SYjI0OVlZXau3dvk39uRvYAAHihpKREVqvVvX+yUf2PuVwu3X333frVr36lXr16SZIcDociIiLUtm1bj7ZJSUlyOBzuNv+d6BvPN55rKpI9AMAcDOP45kt/SVar1SPZN0VOTo4+/vhjvfvuu6d/fx9QxgcAmEJLr8ZvNHHiROXm5urtt99Wp06d3MdtNpvq6up09OhRj/ZlZWWy2WzuNj9end+439imKUj2AAA0A8MwNHHiRK1du1ZvvfWWzj33XI/z/fv3V3h4uDZv3uw+VlRUpOLiYtntdkmS3W7Xnj17VF5e7m6Tl5cnq9WqtLS0JsdCGR8AYA4t/FKdnJwcrVmzRn//+98VFxfnnmOPj49XmzZtFB8fr3HjxmnKlClKSEiQ1WrVpEmTZLfbNXDgQEnS0KFDlZaWpjFjxmjx4sVyOByaOXOmcnJymrRWoBHJHgBgChbX8c2X/t5Yvny5JGnw4MEex1esWKGbb75ZkvTYY48pJCREWVlZqq2tVUZGhp588kl329DQUOXm5mrChAmy2+2KiYlRdna25s+f71UsJHsAAJqB0YTFgFFRUVq2bJmWLVt2yjapqalav369T7GQ7HGC53fsky2l/oTj/1jZXqsW2zRmqkMXXV6lxOQ6VRwJ07YN8Xp+sU3fHQsNQLTAT/vzwzb95VHPhUydzqvRc+98ospvQ/Xnh236ID9O5YcjFJ/QoF8Oq1D2vaWKsf5nGPfkzLO19/0YfV4UpZSutVq+qejHt0FrYOJ345PscYI7h3dTSOh/fqvP6VGjB1/8VO+81lYJSfVqn9SgZ+Z3VPG/opTYqU53PviF2ifV6/7bzglc0MBPSO3+vR588aB7P/SH3+8jZeH6pixc42cfVuduNSr/IkJL7+ukb8rCNeuZzzyukXH9EX3yYbQO7WvTkqHDj/jqXYBs3bpVDz30kAoLC1VaWqq1a9dq5MiRgQwJkiqOeP5a/GZiuQ4fitDughhJFi0Yf477XOnnkVr5fx117xPFCgk15HJaWjZYoAlCQ6WExBM/HHJOjxrNfvYz937yOXW6eXqpFk9KlbNBCv3h/wp33P+lJKniGxvJvjXz03P2rVFAH72rrq5W3759f3KuAoEVFu7SlVnf6s0XEiSdPJHHWJ36riqERI8z1peHInTDhRcoe2BPPZjTWeVfhJ+ybXVlqKJjXe5EDwSDgP46Dx8+XMOHD29y+9raWtXW1rr3f/wxAvjfL4dVKtbq1MaXEk563prQoBvvLtMbf2nfwpEBTdPjompNXfK9Op1XqyPl4frLIzbd8+vz9fTbnyg61nN5dcU3oVqzxKbhN30doGjRnMxcxm9VL9VZtGiRx8cHUlJSAh1S0Mu44Ru9/7ZVR8pOHAlFxzq1YNUhFf8rSn9+pOlvcgJa0iVXHtOgqyvUJa1GFw8+pvv/8qmqKkO19R9tPdpVHwvRrLFd1Llbjcbc0/R3jqMVMfywtVKtKtnPmDFDFRUV7q2kpCTQIQW1xLPrdOFlVdqw5sRRfZsYpx5Y86m+rw7RvHHnyNlACR+tQ2y8U5261OrwZ/95Icl3VSH6/Y3nqU2MS3OeO6SwU1f5gVapVc1KneqbwWgeQ68/oqNfh2nHJs8PPkTHHk/09XUWzbn5XNXXtqp/M8Lkvq8O0eHPIzQk6/jjpdXHjif68AhD81Z+qoioVjx8w08ycxm/VSV7tByLxdDQ3xzRppfbeSy8i451auFfP1VkG5cWTzpH0bFORcc6JUkV34TJ5WKEjzPLH+cla+DQCiV2qtc3jjD9+eGOCg2RBv/6W1UfC9HvbjhPtd+H6N4nDum7qlB9V3W8X3z7BoX+8OqILw9FqKY6VEe+ClNdjUUHPz6+Ir9ztxqFR7TiDGA2Jl6NT7LHSV04qEpJner15gueC++69v5ePft/J0laWfCJx7mxv+ipsi8iWixGoCm+Lg3XojvO0bFvQxXfvkEXXFKtJbn/Utv2Tn20LVaffBAjSbrll54fFTn+cqk6SdKSqZ21uyDWfe6Ood1PaAOcyQKa7KuqqnTgwAH3/qFDh7Rr1y4lJCSoc+fOAYwMH+THKSO57wnHdxfEnvQ4cKb63VOfn/Jc319W6c3Du372Gg/97cDPtsGZjzJ+gOzcuVNXXHGFe3/KlCmSpOzsbK1cuTJAUQEAghKvyw2MwYMHN+lDAQAA4PQxZw8AMAXK+AAABDuXcXzzpX8rRbIHAJiDiefseRsKAABBjpE9AMAULPJxzt5vkbQ8kj0AwBxM/AY9yvgAAAQ5RvYAAFPg0TsAAIIdq/EBAECwYmQPADAFi2HI4sMiO1/6BhrJHgBgDq4fNl/6t1KU8QEACHKM7AEApkAZHwCAYGfi1fgkewCAOfAGPQAAEKxI9gAAU2h8g54vmze2bt2qq6++WsnJybJYLFq3bp3H+ZtvvlkWi8VjGzZsmEebI0eOaPTo0bJarWrbtq3GjRunqqoqr392kj0AwBway/i+bF6orq5W3759tWzZslO2GTZsmEpLS93bX//6V4/zo0eP1t69e5WXl6fc3Fxt3bpVt912m9c/OnP2AAA0g+HDh2v48OE/2SYyMlI2m+2k5/bv368NGzbo/fff18UXXyxJeuKJJzRixAg9/PDDSk5ObnIsjOwBAKZgcfm+SVJlZaXHVltbe9oxbdmyRYmJierevbsmTJigb775xn2uoKBAbdu2dSd6SUpPT1dISIh27Njh1X1I9gAAc/BTGT8lJUXx8fHubdGiRacVzrBhw7Rq1Spt3rxZ//d//6f8/HwNHz5cTqdTkuRwOJSYmOjRJywsTAkJCXI4HF7dizI+AABeKCkpkdVqde9HRkae1nWuv/5695979+6tPn366LzzztOWLVs0ZMgQn+P8b4zsAQDmYPhhk2S1Wj220032P9alSxd16NBBBw4ckCTZbDaVl5d7tGloaNCRI0dOOc9/KiR7AIApNL4u15etOX3xxRf65ptv1LFjR0mS3W7X0aNHVVhY6G7z1ltvyeVyacCAAV5dmzI+AADNoKqqyj1Kl6RDhw5p165dSkhIUEJCgubNm6esrCzZbDYdPHhQ9957r7p27aqMjAxJUs+ePTVs2DCNHz9eTz31lOrr6zVx4kRdf/31Xq3ElxjZAwDMooWfs9+5c6cuvPBCXXjhhZKkKVOm6MILL9Ts2bMVGhqq3bt365prrlG3bt00btw49e/fX++8847HtMDq1avVo0cPDRkyRCNGjNCll16qP/7xj17/6IzsAQDmYMi3b9J7WcUfPHiwjJ/4B8Kbb775s9dISEjQmjVrvLvxSZDsAQCmYOZP3FLGBwAgyDGyBwCYgyEfP3Hrt0haHMkeAGAOfM8eAAAEK0b2AABzcEmy+Ni/lSLZAwBMgdX4AAAgaDGyBwCYg4kX6JHsAQDmYOJkTxkfAIAgx8geAGAOJh7Zk+wBAObAo3cAAAQ3Hr0DAABBi5E9AMAcmLMHACDIuQzJ4kPCdrXeZE8ZHwCAIMfIHgBgDpTxAQAIdj4me7XeZE8ZHwCAIMfIHgBgDpTxAQAIci5DPpXiWY0PAADOVIzsAQDmYLiOb770b6VI9gAAc2DOHgCAIMecPQAACFaM7AEA5kAZHwCAIGfIx2Tvt0haHGV8AACawdatW3X11VcrOTlZFotF69at8zhvGIZmz56tjh07qk2bNkpPT9e///1vjzZHjhzR6NGjZbVa1bZtW40bN05VVVVex0KyBwCYQ2MZ35fNC9XV1erbt6+WLVt20vOLFy/W0qVL9dRTT2nHjh2KiYlRRkaGampq3G1Gjx6tvXv3Ki8vT7m5udq6datuu+02r390yvgAAHNwuST58Ky8y7u+w4cP1/Dhw096zjAMLVmyRDNnztS1114rSVq1apWSkpK0bt06XX/99dq/f782bNig999/XxdffLEk6YknntCIESP08MMPKzk5ucmxMLIHAMALlZWVHlttba3X1zh06JAcDofS09Pdx+Lj4zVgwAAVFBRIkgoKCtS2bVt3opek9PR0hYSEaMeOHV7dj2QPADAHP5XxU1JSFB8f794WLVrkdSgOh0OSlJSU5HE8KSnJfc7hcCgxMdHjfFhYmBISEtxtmooyPgDAHPz06F1JSYmsVqv7cGRkpK+RNTtG9gAAeMFqtXpsp5PsbTabJKmsrMzjeFlZmfuczWZTeXm5x/mGhgYdOXLE3aapSPYAAHNwGb5vfnLuuefKZrNp8+bN7mOVlZXasWOH7Ha7JMlut+vo0aMqLCx0t3nrrbfkcrk0YMAAr+5HGR8AYAqG4ZLhw5frvO1bVVWlAwcOuPcPHTqkXbt2KSEhQZ07d9bdd9+t+++/X+eff77OPfdczZo1S8nJyRo5cqQkqWfPnho2bJjGjx+vp556SvX19Zo4caKuv/56r1biSyR7AIBZGD6Ozr2c79+5c6euuOIK9/6UKVMkSdnZ2Vq5cqXuvfdeVVdX67bbbtPRo0d16aWXasOGDYqKinL3Wb16tSZOnKghQ4YoJCREWVlZWrp0qdehWwyj9b7st7KyUvHx8RqsaxVmCQ90OECzePPwrkCHADSbymMutev2qSoqKjwWvfn1Hj/kiiFtxyrMEnHa12kw6rT56KpmjbW5MLIHAJiD4eMnblvv2JhkDwAwCZdLsvjwBj0f5vsDjdX4AAAEOUb2AABzoIwPAEBwM1wuGT6U8X15bC/QKOMDABDkGNkDAMyBMj4AAEHOZUgWcyZ7yvgAAAQ5RvYAAHMwDEm+PGffekf2JHsAgCkYLkOGD2X8Vvx2eZI9AMAkDJd8G9nz6B0AADhDMbIHAJgCZXwAAIKdicv4rTrZN/4rq0H1Pr0nATiTVR5rvX/BAD+nsur473dLjJp9zRUNqvdfMC2sVSf7Y8eOSZLe1foARwI0n3bdAh0B0PyOHTum+Pj4Zrl2RESEbDab3nX4nitsNpsiIiL8EFXLshiteBLC5XLp8OHDiouLk8ViCXQ4plBZWamUlBSVlJTIarUGOhzAr/j9bnmGYejYsWNKTk5WSEjzrRmvqalRXV2dz9eJiIhQVFSUHyJqWa16ZB8SEqJOnToFOgxTslqt/GWIoMXvd8tqrhH9f4uKimqVSdpfePQOAIAgR7IHACDIkezhlcjISM2ZM0eRkZGBDgXwO36/Eaxa9QI9AADw8xjZAwAQ5Ej2AAAEOZI9AABBjmQPAECQI9mjyZYtW6ZzzjlHUVFRGjBggP75z38GOiTAL7Zu3aqrr75aycnJslgsWrduXaBDAvyKZI8mefHFFzVlyhTNmTNHH3zwgfr27auMjAyVl5cHOjTAZ9XV1erbt6+WLVsW6FCAZsGjd2iSAQMG6JJLLtEf/vAHSce/S5CSkqJJkybpvvvuC3B0gP9YLBatXbtWI0eODHQogN8wssfPqqurU2FhodLT093HQkJClJ6eroKCggBGBgBoCpI9ftbXX38tp9OppKQkj+NJSUlyOBwBigoA0FQkewAAghzJHj+rQ4cOCg0NVVlZmcfxsrIy2Wy2AEUFAGgqkj1+VkREhPr376/Nmze7j7lcLm3evFl2uz2AkQEAmiIs0AGgdZgyZYqys7N18cUX6xe/+IWWLFmi6upq3XLLLYEODfBZVVWVDhw44N4/dOiQdu3apYSEBHXu3DmAkQH+waN3aLI//OEPeuihh+RwONSvXz8tXbpUAwYMCHRYgM+2bNmiK6644oTj2dnZWrlyZcsHBPgZyR4AgCDHnD0AAEGOZA8AQJAj2QMAEORI9gAABDmSPQAAQY5kDwBAkCPZAwAQ5Ej2AAAEOZI94KObb75ZI0eOdO8PHjxYd999d4vHsWXLFlksFh09evSUbSwWi9atW9fka86dO1f9+vXzKa7PPvtMFotFu3bt8uk6AE4fyR5B6eabb5bFYpHFYlFERIS6du2q+fPnq6Ghodnv/eqrr2rBggVNatuUBA0AvuJDOAhaw4YN04oVK1RbW6v169crJydH4eHhmjFjxglt6+rqFBER4Zf7JiQk+OU6AOAvjOwRtCIjI2Wz2ZSamqoJEyYoPT1d//jHPyT9p/T+wAMPKDk5Wd27d5cklZSU6LrrrlPbtm2VkJCga6+9Vp999pn7mk6nU1OmTFHbtm3Vvn173Xvvvfrx5yV+XMavra3V9OnTlZKSosjISHXt2lXPPfecPvvsM/fHV9q1ayeLxaKbb75Z0vFPCC9atEjnnnuu2rRpo759++qVV17xuM/69evVrVs3tWnTRldccYVHnE01ffp0devWTdHR0erSpYtmzZql+vr6E9o9/fTTSklJUXR0tK677jpVVFR4nH/22WfVs2dPRUVFqUePHnryySe9jgVA8yHZwzTatGmjuro69/7mzZtVVFSkvLw85ebmqr6+XhkZGYqLi9M777yj9957T7GxsRo2bJi73yOPPKKVK1fqT3/6k959910dOXJEa9eu/cn7jh07Vn/961+1dOlS7d+/X08//bRiY2OVkpKiv/3tb5KkoqIilZaW6vHHH5ckLVq0SKtWrdJTTz2lvXv3avLkybrpppuUn58v6fg/SkaNGqWrr75au3bt0q233qr77rvP6/9O4uLitHLlSu3bt0+PP/64nnnmGT322GMebQ4cOKCXXnpJr732mjZs2KAPP/xQd9xxh/v86tWrNXv2bD3wwAPav3+/Fi5cqFmzZun555/3Oh4AzcQAglB2drZx7bXXGoZhGC6Xy8jLyzMiIyONqVOnus8nJSUZtbW17j5//vOfje7duxsul8t9rLa21mjTpo3x5ptvGoZhGB07djQWL17sPl9fX2906tTJfS/DMIzLL7/cuOuuuwzDMIyioiJDkpGXl3fSON9++21DkvHtt9+6j9XU1BjR0dHGtm3bPNqOGzfOuOGGGwzDMIwZM2YYaWlpHuenT59+wrV+TJKxdu3aU55/6KGHjP79+7v358yZY4SGhhpffPGF+9gbb7xhhISEGKWlpYZhGMZ5551nrFmzxuM6CxYsMOx2u2EYhnHo0CFDkvHhhx+e8r4Amhdz9ghaubm5io2NVX19vVwul2688UbNnTvXfb53794e8/QfffSRDhw4oLi4OI/r1NTU6ODBg6qoqFBpaakGDBjgPhcWFqaLL774hFJ+o127dik0NFSXX355k+M+cOCAvvvuO1111VUex+vq6nThhRdKkvbv3+8RhyTZ7fYm36PRiy++qKVLl+rgwYOqqqpSQ0ODrFarR5vOnTvr7LPP9riPy+VSUVGR4uLidPDgQY0bN07jx493t2loaFB8fLzX8QBoHiR7BK0rrrhCy5cvV0REhJKTkxUW5vnrHhMT47FfVVWl/v37a/Xq1Sdc66yzzjqtGNq0aeN1n6qqKknS66+/7pFkpePrEPyloKBAo0eP1rx585SRkaH4+Hi98MILeuSRR7yO9ZlnnjnhHx+hoaF+ixWAb0j2CFoxMTHq2rVrk9tfdNFFevHFF5WYmHjC6LZRx44dtWPHDg0aNEjS8RFsYWGhLrroopO27927t1wul/Lz85Wenn7C+cbKgtPpdB9LS0tTZGSkiouLT1kR6Nmzp3uxYaPt27f//A/5X7Zt26bU1FT9/ve/dx/7/PPPT2hXXFysw4cPKzk52X2fkJAQde/eXUlJSUpOTtann36q0aNHe3V/AC2HBXrAD0aPHq0OHTro2muv1TvvvKNDhw5py5YtuvPOO/XFF19Iku666y49+OCDWrdunT755BPdcccdP/mM/DnnnKPs7Gz99re/1bp169zXfOmllyRJqampslgsys3N1VdffaWqqirFxcVp6tSpmjx5sp5//nkdPHhQH3zwgZ544gn3orfbb79d//73vzVt2jQVFRVpzZo1WrlypVc/7/nnn6/i4mK98MILOnjwoJYuXXrSxYZRUVHKzs7WRx99pHfeeUd33nmnrrvuOtlsNknSvHnztGjRIi1dulT/+te/tGfPHq1YsUKPPvqoV/EAaD4ke+AH0dHR2rp1qzp37qxRo0apZ8+eGjdunGpqatwj/XvuuUdjxoxRdna27Ha74uLi9Otf//onr7t8+XL9z//8j+644w716NFD48ePV3V1tSTp7LPP1rx583TfffcpKSlJEydOlCQtWLBAs2bN0qJFi9SzZ08NGzZMr7/+us4991xJx+fR//a3v2ndunXq27evnnrqKS1cuNCrn/eaa67R5MmTNXHiRPXr10/btm3TrFmzTmjXtWtXjRo1SiNGjNDQoUPVp08fj0frbr31Vj377LNasWKFevfurcsvv1wrV650xwog8CzGqVYWAQCAoMDIHgCAIEeyBwAgyJHsAQAIciR7AACCHMkeAIAgR7IHACDIkewBAAhyJHsAAIIcyR4AgCBHsgcAIMiR7AEACHL/P9xeWtFDPzc2AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "melhor=0\n",
    "\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid','linear']}\n",
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=0);\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "grid_predictions = grid.predict(X_test)\n",
    "print(classification_report(y_test,grid_predictions))\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, grid_predictions)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.864592094196804\n",
      "Precision: 0.8506493506493507\n",
      "Recall: 0.8836424957841484\n",
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "melhor=0\n",
    "\n",
    "for k in range(1,100):\n",
    "    # Você pode ajustar esse valor\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # Treine o classificador com os dados de treinamento\n",
    "    knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Faça previsões no conjunto de teste\n",
    "    y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "    # Calcule a precisão das previsões\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    if accuracy>melhor:\n",
    "        melhork=k\n",
    "        melhor=accuracy\n",
    "        melhorp=precision\n",
    "        melhorr=recall\n",
    "print(f\"Acurácia: {melhor}\")\n",
    "print(\"Precision:\", melhorp)\n",
    "print(\"Recall:\", melhorr)\n",
    "print(melhork)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Campião\\LIACD\\A3-S1\\LabIACD\\LungCancer\\LabIACDreal.ipynb Cell 47\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Campi%C3%A3o/LIACD/A3-S1/LabIACD/LungCancer/LabIACDreal.ipynb#Y240sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Campi%C3%A3o/LIACD/A3-S1/LabIACD/LungCancer/LabIACDreal.ipynb#Y240sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# Treine o modelo\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Campi%C3%A3o/LIACD/A3-S1/LabIACD/LungCancer/LabIACDreal.ipynb#Y240sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X, y, epochs\u001b[39m=\u001b[39;49mepochs, batch_size\u001b[39m=\u001b[39;49mbatch_size, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Campi%C3%A3o/LIACD/A3-S1/LabIACD/LungCancer/LabIACDreal.ipynb#Y240sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# Avalie o modelo\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Campi%C3%A3o/LIACD/A3-S1/LabIACD/LungCancer/LabIACDreal.ipynb#Y240sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m loss, accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_test\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist(), y_test, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[0;32m    869\u001b[0m   )\n\u001b[0;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suponha que você tenha um DataFrame 'X_train' com suas features e uma Serie 'y_train' com os rótulos/targets\n",
    "\n",
    "# Convertemos X_train e y_train para arrays NumPy\n",
    "X_NN = X_train.values.tolist()\n",
    "y_NN = y_train\n",
    "\n",
    "# Defina listas de parâmetros a serem testados\n",
    "hidden_layer_sizes = [(12, 8), (10, 6), (8, 4)]\n",
    "epochs_list = [100, 150, 200]\n",
    "batch_size_list = [5, 10, 20]\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "\n",
    "# Listas para armazenar accuracy e loss\n",
    "accuracies = []\n",
    "losses = []\n",
    "\n",
    "# Itere sobre as diferentes combinações de parâmetros\n",
    "for hidden_layers in hidden_layer_sizes:\n",
    "    for epochs in epochs_list:\n",
    "        for batch_size in batch_size_list:\n",
    "            # Crie o modelo\n",
    "            model = Sequential()\n",
    "            for units in hidden_layers:\n",
    "                model.add(Dense(units, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            \n",
    "            # Compile o modelo\n",
    "            model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "            \n",
    "            # Treine o modelo\n",
    "            history = model.fit(X_NN, y_NN, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "            \n",
    "            # Avalie o modelo\n",
    "            loss, accuracy = model.evaluate(X_test.values.tolist(), y_test, verbose=0)\n",
    "            \n",
    "            # Armazene accuracy e loss\n",
    "            accuracies.append(accuracy)\n",
    "            losses.append(loss)\n",
    "            \n",
    "            # Verifique se este é o melhor modelo até agora\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_model = model\n",
    "print('Melhor accuracy: ', best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 1ms/step\n",
      "[[3.6310684e-02]\n",
      " [9.7882789e-01]\n",
      " [8.0281422e-02]\n",
      " ...\n",
      " [2.3186735e-06]\n",
      " [9.9999458e-01]\n",
      " [9.9515969e-01]]\n",
      "[0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87       598\n",
      "           1       0.86      0.89      0.87       591\n",
      "\n",
      "    accuracy                           0.87      1189\n",
      "   macro avg       0.87      0.87      0.87      1189\n",
      "weighted avg       0.87      0.87      0.87      1189\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_predictions = best_model.predict(X_test)\n",
    "\n",
    "count=0\n",
    "f=[0]*len(grid_predictions)\n",
    "for value in grid_predictions:\n",
    "    if value>=0.5:\n",
    "        f[count]=1\n",
    "    else:\n",
    "        f[count]=0\n",
    "    count+=1\n",
    "\n",
    "\n",
    "print(classification_report(y_test,f))\n",
    "\n",
    "cm = confusion_matrix(y_test, f)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de resultados e conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
